{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FinOps Copilot - Complete Deployment and Testing Guide\n",
    "\n",
    "This notebook provides comprehensive documentation for deploying and testing the FinOps Copilot solution, including:\n",
    "- Lambda Functions\n",
    "- AWS Bedrock Agents\n",
    "- MCP Servers\n",
    "- Streamlit Frontend\n",
    "- Testing Framework\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "1. [Architecture Overview](#architecture-overview)\n",
    "2. [Lambda Functions](#lambda-functions)\n",
    "3. [AWS Bedrock Agents](#bedrock-agents)\n",
    "4. [MCP Servers](#mcp-servers)\n",
    "5. [Streamlit Frontend](#streamlit-frontend)\n",
    "6. [Deployment with AWS CLI](#deployment)\n",
    "7. [Testing](#testing)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Architecture Overview <a id='architecture-overview'></a>\n",
    "\n",
    "FinOps Copilot is a comprehensive AWS cost optimization solution that combines:\n",
    "\n",
    "- **Lambda Functions**: Service-specific cost analyzers (EC2, S3, RDS, etc.)\n",
    "- **Bedrock Agents**: AI-powered orchestration and recommendations\n",
    "- **MCP Servers**: Model Context Protocol servers for data integration\n",
    "- **Streamlit Frontend**: Interactive dashboard for visualization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Lambda Functions <a id='lambda-functions'></a>\n",
    "\n",
    "### 2.1 EC2 Agent\n",
    "\n",
    "The EC2 Agent analyzes EC2 instance utilization and provides optimization recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EC2 Agent Lambda Handler\n",
    "# File: lambda-functions/ec2_agent.py\n",
    "\n",
    "import json\n",
    "import boto3\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "class EC2CostAnalyzer:\n",
    "    \"\"\"Analyzes EC2 costs and provides optimization recommendations\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.ec2_client = boto3.client('ec2')\n",
    "        self.cloudwatch_client = boto3.client('cloudwatch')\n",
    "        self.cost_explorer_client = boto3.client('ce')\n",
    "    \n",
    "    def analyze_instance_utilization(self, instance_ids, days=30):\n",
    "        \"\"\"Analyze CPU utilization for specified instances\"\"\"\n",
    "        # Implementation details in the actual file\n",
    "        pass\n",
    "    \n",
    "    def identify_optimization_opportunities(self, utilization_data, instance_details, cost_data):\n",
    "        \"\"\"Identify cost optimization opportunities based on utilization\"\"\"\n",
    "        # Implementation details in the actual file\n",
    "        pass\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    \"\"\"AWS Lambda handler for EC2 cost analysis\"\"\"\n",
    "    analyzer = EC2CostAnalyzer()\n",
    "    action = event.get('action', 'analyze_all')\n",
    "    \n",
    "    if action == 'analyze_all':\n",
    "        # Comprehensive analysis of all instances\n",
    "        pass\n",
    "    elif action == 'analyze_utilization':\n",
    "        # Analyze utilization only\n",
    "        pass\n",
    "    elif action == 'get_recommendations':\n",
    "        # Get optimization recommendations\n",
    "        pass\n",
    "    \n",
    "    return {\n",
    "        'statusCode': 200,\n",
    "        'body': json.dumps(result)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 S3 Agent\n",
    "\n",
    "The S3 Agent analyzes S3 bucket usage and provides storage optimization recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3 Agent Lambda Handler\n",
    "# File: lambda-functions/s3_agent.py\n",
    "\n",
    "class S3CostAnalyzer:\n",
    "    \"\"\"Analyzes S3 costs and provides optimization recommendations\"\"\"\n",
    "    \n",
    "    def analyze_bucket_storage(self):\n",
    "        \"\"\"Analyze storage usage across all buckets\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def analyze_storage_classes(self, bucket_name):\n",
    "        \"\"\"Analyze storage class distribution\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def identify_optimization_opportunities(self, bucket_analysis, cost_data):\n",
    "        \"\"\"Identify S3 optimization opportunities\"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Orchestrator Agent\n",
    "\n",
    "The Orchestrator Agent coordinates between different service agents and provides comprehensive analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Orchestrator Agent Lambda Handler\n",
    "# File: lambda-functions/orchestrator_agent.py\n",
    "\n",
    "class FinOpsOrchestrator:\n",
    "    \"\"\"Orchestrates cost optimization across AWS services\"\"\"\n",
    "    \n",
    "    def process_query(self, query):\n",
    "        \"\"\"Process natural language queries about cost optimization\"\"\"\n",
    "        # Use Bedrock to understand intent\n",
    "        # Call appropriate service agents\n",
    "        # Aggregate and format results\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. AWS Bedrock Agents <a id='bedrock-agents'></a>\n",
    "\n",
    "### 3.1 Bedrock Agent Configuration\n",
    "\n",
    "Bedrock Agents provide AI-powered analysis and recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bedrock Agent Configuration\n",
    "# File: bedrock-agents/orchestrator_agent_config.json\n",
    "\n",
    "orchestrator_config = {\n",
    "    \"agentName\": \"FinOpsOrchestratorAgent\",\n",
    "    \"description\": \"Orchestrates cost optimization analysis across AWS services\",\n",
    "    \"foundationModel\": \"anthropic.claude-v2\",\n",
    "    \"instructions\": \"\"\"You are a FinOps expert assistant that helps users optimize \n",
    "                       their AWS costs. Analyze user queries and coordinate with \n",
    "                       service-specific agents to provide comprehensive recommendations.\"\"\",\n",
    "    \"actionGroups\": [\n",
    "        {\n",
    "            \"actionGroupName\": \"EC2Actions\",\n",
    "            \"description\": \"Actions for EC2 cost analysis\",\n",
    "            \"lambdaFunction\": \"finops-ec2-agent\"\n",
    "        },\n",
    "        {\n",
    "            \"actionGroupName\": \"S3Actions\",\n",
    "            \"description\": \"Actions for S3 cost analysis\",\n",
    "            \"lambdaFunction\": \"finops-s3-agent\"\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Action Group API Schema\n",
    "\n",
    "Define the API schema for Bedrock agent action groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Action Group API Schema\n",
    "# File: bedrock-agents/service-agent-api-schema.yaml\n",
    "\n",
    "api_schema = \"\"\"\n",
    "openapi: 3.0.0\n",
    "info:\n",
    "  title: FinOps Service Agent API\n",
    "  version: 1.0.0\n",
    "paths:\n",
    "  /analyze:\n",
    "    post:\n",
    "      summary: Analyze service costs\n",
    "      requestBody:\n",
    "        required: true\n",
    "        content:\n",
    "          application/json:\n",
    "            schema:\n",
    "              type: object\n",
    "              properties:\n",
    "                action:\n",
    "                  type: string\n",
    "                  enum: [analyze_all, analyze_utilization, get_recommendations]\n",
    "                days:\n",
    "                  type: integer\n",
    "                  default: 30\n",
    "                instance_ids:\n",
    "                  type: array\n",
    "                  items:\n",
    "                    type: string\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. MCP Servers <a id='mcp-servers'></a>\n",
    "\n",
    "### 4.1 Cost Explorer MCP Server\n",
    "\n",
    "MCP server for AWS Cost Explorer integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost Explorer MCP Server\n",
    "# File: mcp-servers/cost_explorer_mcp.py\n",
    "\n",
    "class CostExplorerMCPServer:\n",
    "    \"\"\"MCP server for AWS Cost Explorer data\"\"\"\n",
    "    \n",
    "    async def process_mcp_request(self, request):\n",
    "        \"\"\"Process incoming MCP requests\"\"\"\n",
    "        method = request.get('method')\n",
    "        \n",
    "        if method == 'cost_explorer.get_cost_and_usage':\n",
    "            return await self.get_cost_and_usage(\n",
    "                request['params']['timePeriod'],\n",
    "                request['params']['granularity'],\n",
    "                request['params']['metrics'],\n",
    "                request['params'].get('groupBy')\n",
    "            )\n",
    "        # Additional methods...\n",
    "\n",
    "class MCPProtocolHandler:\n",
    "    \"\"\"Handles MCP protocol communication\"\"\"\n",
    "    \n",
    "    async def handle_request(self, request_data):\n",
    "        \"\"\"Handle incoming MCP request following JSON-RPC 2.0\"\"\"\n",
    "        # Parse request, route to appropriate handler, format response\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Streamlit Frontend <a id='streamlit-frontend'></a>\n",
    "\n",
    "### 5.1 Main Application\n",
    "\n",
    "The Streamlit frontend provides an interactive dashboard for cost analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Streamlit Frontend Application\n",
    "# File: frontend/app.py\n",
    "\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import boto3\n",
    "\n",
    "def main():\n",
    "    st.set_page_config(\n",
    "        page_title=\"FinOps Copilot\",\n",
    "        page_icon=\"💰\",\n",
    "        layout=\"wide\"\n",
    "    )\n",
    "    \n",
    "    st.title(\"FinOps Copilot - AWS Cost Optimization Dashboard\")\n",
    "    \n",
    "    # Sidebar for navigation\n",
    "    page = st.sidebar.selectbox(\n",
    "        \"Navigation\",\n",
    "        [\"Overview\", \"EC2 Analysis\", \"S3 Analysis\", \"Recommendations\"]\n",
    "    )\n",
    "    \n",
    "    if page == \"Overview\":\n",
    "        show_overview()\n",
    "    elif page == \"EC2 Analysis\":\n",
    "        show_ec2_analysis()\n",
    "    # Additional pages...\n",
    "\n",
    "def show_overview():\n",
    "    \"\"\"Display cost overview dashboard\"\"\"\n",
    "    col1, col2, col3, col4 = st.columns(4)\n",
    "    \n",
    "    with col1:\n",
    "        st.metric(\"Total Monthly Cost\", \"$12,450\", \"+5%\")\n",
    "    with col2:\n",
    "        st.metric(\"Potential Savings\", \"$2,890\", \"-23%\")\n",
    "    # Additional metrics...\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Deployment with AWS CLI <a id='deployment'></a>\n",
    "\n",
    "### 6.1 Prerequisites\n",
    "\n",
    "Ensure you have the following installed:\n",
    "- AWS CLI (v2.x)\n",
    "- Python 3.8+\n",
    "- Docker (for Lambda container images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Check AWS CLI version\n",
    "aws --version\n",
    "\n",
    "# Configure AWS credentials if not already done\n",
    "# aws configure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Deploy Lambda Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Set environment variables\n",
    "export ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)\n",
    "export REGION=\"us-east-1\"\n",
    "export LAMBDA_ROLE_NAME=\"finops-lambda-role\"\n",
    "\n",
    "# Create IAM role for Lambda functions\n",
    "cat > trust-policy.json << EOF\n",
    "{\n",
    "  \"Version\": \"2012-10-17\",\n",
    "  \"Statement\": [\n",
    "    {\n",
    "      \"Effect\": \"Allow\",\n",
    "      \"Principal\": {\n",
    "        \"Service\": \"lambda.amazonaws.com\"\n",
    "      },\n",
    "      \"Action\": \"sts:AssumeRole\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "EOF\n",
    "\n",
    "aws iam create-role \\\n",
    "  --role-name $LAMBDA_ROLE_NAME \\\n",
    "  --assume-role-policy-document file://trust-policy.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Attach necessary policies to the Lambda role\n",
    "aws iam attach-role-policy \\\n",
    "  --role-name $LAMBDA_ROLE_NAME \\\n",
    "  --policy-arn arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole\n",
    "\n",
    "aws iam attach-role-policy \\\n",
    "  --role-name $LAMBDA_ROLE_NAME \\\n",
    "  --policy-arn arn:aws:iam::aws:policy/AWSCostExplorerReadOnlyAccess\n",
    "\n",
    "aws iam attach-role-policy \\\n",
    "  --role-name $LAMBDA_ROLE_NAME \\\n",
    "  --policy-arn arn:aws:iam::aws:policy/AmazonEC2ReadOnlyAccess\n",
    "\n",
    "aws iam attach-role-policy \\\n",
    "  --role-name $LAMBDA_ROLE_NAME \\\n",
    "  --policy-arn arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\n",
    "\n",
    "aws iam attach-role-policy \\\n",
    "  --role-name $LAMBDA_ROLE_NAME \\\n",
    "  --policy-arn arn:aws:iam::aws:policy/CloudWatchReadOnlyAccess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Package and deploy EC2 Agent Lambda\n",
    "cd lambda-functions\n",
    "\n",
    "# Create deployment package\n",
    "zip -r ec2-agent.zip ec2_agent.py\n",
    "\n",
    "# Create Lambda function\n",
    "aws lambda create-function \\\n",
    "  --function-name finops-ec2-agent \\\n",
    "  --runtime python3.9 \\\n",
    "  --role arn:aws:iam::${ACCOUNT_ID}:role/${LAMBDA_ROLE_NAME} \\\n",
    "  --handler ec2_agent.lambda_handler \\\n",
    "  --zip-file fileb://ec2-agent.zip \\\n",
    "  --timeout 300 \\\n",
    "  --memory-size 512 \\\n",
    "  --environment Variables='{\"LOG_LEVEL\":\"INFO\"}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Deploy S3 Agent Lambda\n",
    "zip -r s3-agent.zip s3_agent.py\n",
    "\n",
    "aws lambda create-function \\\n",
    "  --function-name finops-s3-agent \\\n",
    "  --runtime python3.9 \\\n",
    "  --role arn:aws:iam::${ACCOUNT_ID}:role/${LAMBDA_ROLE_NAME} \\\n",
    "  --handler s3_agent.lambda_handler \\\n",
    "  --zip-file fileb://s3-agent.zip \\\n",
    "  --timeout 300 \\\n",
    "  --memory-size 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Deploy Orchestrator Agent Lambda\n",
    "zip -r orchestrator-agent.zip orchestrator_agent.py\n",
    "\n",
    "aws lambda create-function \\\n",
    "  --function-name finops-orchestrator-agent \\\n",
    "  --runtime python3.9 \\\n",
    "  --role arn:aws:iam::${ACCOUNT_ID}:role/${LAMBDA_ROLE_NAME} \\\n",
    "  --handler orchestrator_agent.lambda_handler \\\n",
    "  --zip-file fileb://orchestrator-agent.zip \\\n",
    "  --timeout 300 \\\n",
    "  --memory-size 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Deploy Bedrock Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Create IAM role for Bedrock Agent\n",
    "cat > bedrock-trust-policy.json << EOF\n",
    "{\n",
    "  \"Version\": \"2012-10-17\",\n",
    "  \"Statement\": [\n",
    "    {\n",
    "      \"Effect\": \"Allow\",\n",
    "      \"Principal\": {\n",
    "        \"Service\": \"bedrock.amazonaws.com\"\n",
    "      },\n",
    "      \"Action\": \"sts:AssumeRole\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "EOF\n",
    "\n",
    "aws iam create-role \\\n",
    "  --role-name finops-bedrock-agent-role \\\n",
    "  --assume-role-policy-document file://bedrock-trust-policy.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Create Bedrock Agent\n",
    "aws bedrock-agent create-agent \\\n",
    "  --agent-name \"FinOpsOrchestratorAgent\" \\\n",
    "  --agent-resource-role-arn arn:aws:iam::${ACCOUNT_ID}:role/finops-bedrock-agent-role \\\n",
    "  --foundation-model \"anthropic.claude-v2\" \\\n",
    "  --instruction \"You are a FinOps expert assistant that helps users optimize their AWS costs.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Create action group for EC2 analysis\n",
    "aws bedrock-agent create-agent-action-group \\\n",
    "  --agent-id <AGENT_ID> \\\n",
    "  --agent-version DRAFT \\\n",
    "  --action-group-name \"EC2Actions\" \\\n",
    "  --action-group-executor '{\"lambda\":\"arn:aws:lambda:${REGION}:${ACCOUNT_ID}:function:finops-ec2-agent\"}' \\\n",
    "  --api-schema '{\"s3\":{\"s3BucketName\":\"<BUCKET>\",\"s3ObjectKey\":\"service-agent-api-schema.yaml\"}}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Deploy MCP Servers\n",
    "\n",
    "MCP servers can be deployed as Lambda functions or ECS services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Package and deploy Cost Explorer MCP as Lambda\n",
    "cd mcp-servers\n",
    "\n",
    "# Create requirements.txt\n",
    "cat > requirements.txt << EOF\n",
    "boto3\n",
    "botocore\n",
    "python-dateutil\n",
    "EOF\n",
    "\n",
    "# Install dependencies\n",
    "pip install -r requirements.txt -t .\n",
    "\n",
    "# Create deployment package\n",
    "zip -r cost-explorer-mcp.zip .\n",
    "\n",
    "# Deploy as Lambda function\n",
    "aws lambda create-function \\\n",
    "  --function-name finops-cost-explorer-mcp \\\n",
    "  --runtime python3.9 \\\n",
    "  --role arn:aws:iam::${ACCOUNT_ID}:role/${LAMBDA_ROLE_NAME} \\\n",
    "  --handler cost_explorer_mcp.lambda_handler \\\n",
    "  --zip-file fileb://cost-explorer-mcp.zip \\\n",
    "  --timeout 60 \\\n",
    "  --memory-size 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 Deploy Streamlit Frontend on AWS App Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Create Dockerfile for Streamlit app\n",
    "cd frontend\n",
    "\n",
    "cat > Dockerfile << EOF\n",
    "FROM python:3.9-slim\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "COPY requirements.txt .\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "COPY . .\n",
    "\n",
    "EXPOSE 8501\n",
    "\n",
    "CMD [\"streamlit\", \"run\", \"app.py\", \"--server.port=8501\", \"--server.address=0.0.0.0\"]\n",
    "EOF\n",
    "\n",
    "# Build and push to ECR\n",
    "aws ecr create-repository --repository-name finops-copilot-frontend\n",
    "\n",
    "# Get ECR login token\n",
    "aws ecr get-login-password --region ${REGION} | docker login --username AWS --password-stdin ${ACCOUNT_ID}.dkr.ecr.${REGION}.amazonaws.com\n",
    "\n",
    "# Build and push image\n",
    "docker build -t finops-copilot-frontend .\n",
    "docker tag finops-copilot-frontend:latest ${ACCOUNT_ID}.dkr.ecr.${REGION}.amazonaws.com/finops-copilot-frontend:latest\n",
    "docker push ${ACCOUNT_ID}.dkr.ecr.${REGION}.amazonaws.com/finops-copilot-frontend:latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Create App Runner service\n",
    "aws apprunner create-service \\\n",
    "  --service-name \"finops-copilot-frontend\" \\\n",
    "  --source-configuration '{\n",
    "    \"ImageRepository\": {\n",
    "      \"ImageIdentifier\": \"'${ACCOUNT_ID}'.dkr.ecr.'${REGION}'.amazonaws.com/finops-copilot-frontend:latest\",\n",
    "      \"ImageConfiguration\": {\n",
    "        \"Port\": \"8501\"\n",
    "      },\n",
    "      \"ImageRepositoryType\": \"ECR\"\n",
    "    },\n",
    "    \"AutoDeploymentsEnabled\": false\n",
    "  }'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Testing <a id='testing'></a>\n",
    "\n",
    "### 7.1 Unit Testing\n",
    "\n",
    "Run unit tests for Lambda functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Install test dependencies\n",
    "pip install pytest pytest-cov boto3 moto\n",
    "\n",
    "# Run unit tests\n",
    "cd /home/ec2-user/finops/aws-finops/finops-copilot\n",
    "python -m pytest tests/unit/ -v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Integration Testing\n",
    "\n",
    "Test Lambda functions with AWS services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Test EC2 Agent Lambda\n",
    "aws lambda invoke \\\n",
    "  --function-name finops-ec2-agent \\\n",
    "  --payload '{\n",
    "    \"action\": \"analyze_all\",\n",
    "    \"days\": 7\n",
    "  }' \\\n",
    "  response.json\n",
    "\n",
    "cat response.json | jq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Test S3 Agent Lambda\n",
    "aws lambda invoke \\\n",
    "  --function-name finops-s3-agent \\\n",
    "  --payload '{\n",
    "    \"action\": \"analyze_all\",\n",
    "    \"days\": 30\n",
    "  }' \\\n",
    "  response.json\n",
    "\n",
    "cat response.json | jq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Frontend Testing\n",
    "\n",
    "Test the Streamlit frontend application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Streamlit app locally\n",
    "import subprocess\n",
    "import time\n",
    "import requests\n",
    "\n",
    "# Start Streamlit app\n",
    "process = subprocess.Popen(\n",
    "    [\"streamlit\", \"run\", \"frontend/app.py\"],\n",
    "    stdout=subprocess.PIPE,\n",
    "    stderr=subprocess.PIPE\n",
    ")\n",
    "\n",
    "# Wait for app to start\n",
    "time.sleep(5)\n",
    "\n",
    "# Test if app is running\n",
    "try:\n",
    "    response = requests.get(\"http://localhost:8501\")\n",
    "    print(f\"Frontend status: {response.status_code}\")\n",
    "    print(\"Frontend is running successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error accessing frontend: {e}\")\n",
    "finally:\n",
    "    # Stop the process\n",
    "    process.terminate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4 End-to-End Testing\n",
    "\n",
    "Test the complete flow from frontend to Lambda functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate end-to-end test\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "def test_e2e_flow():\n",
    "    \"\"\"Test the complete FinOps Copilot flow\"\"\"\n",
    "    \n",
    "    # 1. Call Orchestrator Agent\n",
    "    lambda_client = boto3.client('lambda')\n",
    "    \n",
    "    response = lambda_client.invoke(\n",
    "        FunctionName='finops-orchestrator-agent',\n",
    "        InvocationType='RequestResponse',\n",
    "        Payload=json.dumps({\n",
    "            \"query\": \"What are my biggest cost optimization opportunities?\",\n",
    "            \"services\": [\"ec2\", \"s3\"]\n",
    "        })\n",
    "    )\n",
    "    \n",
    "    result = json.loads(response['Payload'].read())\n",
    "    print(\"Orchestrator Response:\")\n",
    "    print(json.dumps(result, indent=2))\n",
    "    \n",
    "    # 2. Verify response structure\n",
    "    assert 'statusCode' in result\n",
    "    assert result['statusCode'] == 200\n",
    "    assert 'body' in result\n",
    "    \n",
    "    body = json.loads(result['body'])\n",
    "    assert 'recommendations' in body\n",
    "    assert 'total_savings' in body\n",
    "    \n",
    "    print(\"\\n✅ End-to-end test passed!\")\n",
    "\n",
    "# Run the test\n",
    "test_e2e_flow()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.5 Performance Testing\n",
    "\n",
    "Test Lambda function performance and latency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import statistics\n",
    "import concurrent.futures\n",
    "\n",
    "def performance_test_lambda(function_name, payload, num_requests=10):\n",
    "    \"\"\"Performance test for Lambda functions\"\"\"\n",
    "    lambda_client = boto3.client('lambda')\n",
    "    latencies = []\n",
    "    \n",
    "    def invoke_lambda():\n",
    "        start_time = time.time()\n",
    "        response = lambda_client.invoke(\n",
    "            FunctionName=function_name,\n",
    "            InvocationType='RequestResponse',\n",
    "            Payload=json.dumps(payload)\n",
    "        )\n",
    "        latency = (time.time() - start_time) * 1000  # Convert to ms\n",
    "        return latency\n",
    "    \n",
    "    # Run concurrent requests\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n",
    "        futures = [executor.submit(invoke_lambda) for _ in range(num_requests)]\n",
    "        latencies = [f.result() for f in concurrent.futures.as_completed(futures)]\n",
    "    \n",
    "    # Calculate statistics\n",
    "    print(f\"\\nPerformance Test Results for {function_name}:\")\n",
    "    print(f\"  Requests: {num_requests}\")\n",
    "    print(f\"  Min latency: {min(latencies):.2f} ms\")\n",
    "    print(f\"  Max latency: {max(latencies):.2f} ms\")\n",
    "    print(f\"  Mean latency: {statistics.mean(latencies):.2f} ms\")\n",
    "    print(f\"  Median latency: {statistics.median(latencies):.2f} ms\")\n",
    "    print(f\"  95th percentile: {statistics.quantiles(latencies, n=20)[18]:.2f} ms\")\n",
    "\n",
    "# Test EC2 Agent performance\n",
    "performance_test_lambda(\n",
    "    'finops-ec2-agent',\n",
    "    {'action': 'analyze_all', 'days': 7}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook provides a comprehensive guide for deploying and testing the FinOps Copilot solution:\n",
    "\n",
    "1. **Lambda Functions**: Deployed service-specific cost analyzers\n",
    "2. **Bedrock Agents**: Created AI-powered orchestration agents\n",
    "3. **MCP Servers**: Deployed data integration servers\n",
    "4. **Streamlit Frontend**: Deployed interactive dashboard on App Runner\n",
    "5. **Testing**: Comprehensive unit, integration, and E2E tests\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. Configure CloudWatch alarms for monitoring\n",
    "2. Set up CI/CD pipeline with AWS CodePipeline\n",
    "3. Implement additional cost optimization features\n",
    "4. Add more comprehensive test coverage\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}