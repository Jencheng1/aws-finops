{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": "# AI for FinOps: Complete Documentation and Implementation Guide\n\nThis notebook provides a comprehensive guide to implementing AI-powered FinOps solutions using AWS services, including Bedrock Agents, Lambda functions, MCP (Model Context Protocol), and an integrated AI chatbot.\n\n## Table of Contents\n1. [System Architecture Overview](#architecture)\n2. [What is MCP (Model Context Protocol)?](#mcp)\n3. [AWS Bedrock Agents Overview](#bedrock)\n4. [Step-by-Step AWS CLI Deployment](#deployment)\n5. [Lambda Functions Implementation](#lambda)\n6. [AI Agent Code and Action Groups](#agents)\n7. [How AWS Agents Work Together](#collaboration)\n8. [Prompts and LLMs Configuration](#prompts)\n9. [Complete Implementation Examples](#examples)\n10. [Streamlit Dashboard with Integrated Chatbot](#chatbot)"
  },
  {
   "cell_type": "markdown",
   "id": "architecture",
   "metadata": {},
   "source": [
    "## 1. System Architecture Overview <a name=\"architecture\"></a>\n",
    "\n",
    "The AI FinOps system consists of multiple components working together to provide intelligent cost optimization:\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────┐\n",
    "│                     User Interface Layer                     │\n",
    "│  (Web App / CLI / API Gateway)                             │\n",
    "└─────────────────────┬───────────────────────────────────────┘\n",
    "                      │\n",
    "┌─────────────────────▼───────────────────────────────────────┐\n",
    "│                  AWS Bedrock Agents                          │\n",
    "│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐        │\n",
    "│  │Cost Analyzer│  │ Optimizer   │  │ Forecaster  │        │\n",
    "│  │   Agent     │  │   Agent     │  │   Agent     │        │\n",
    "│  └──────┬──────┘  └──────┬──────┘  └──────┬──────┘        │\n",
    "└─────────┼────────────────┼────────────────┼────────────────┘\n",
    "          │                │                │\n",
    "┌─────────▼────────────────▼────────────────▼────────────────┐\n",
    "│              Action Groups (Lambda Functions)               │\n",
    "│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐        │\n",
    "│  │getCostData()│  │optimizeRes()│  │forecastCost│        │\n",
    "│  │analyzeCost()│  │recommend()  │  │alertSetup()│        │\n",
    "│  └─────────────┘  └─────────────┘  └─────────────┘        │\n",
    "└─────────────────────┬───────────────────────────────────────┘\n",
    "                      │\n",
    "┌─────────────────────▼───────────────────────────────────────┐\n",
    "│                    AWS Services Layer                        │\n",
    "│  ┌──────────┐  ┌──────────┐  ┌──────────┐  ┌──────────┐   │\n",
    "│  │  Cost    │  │    S3    │  │CloudWatch│  │   RDS    │   │\n",
    "│  │ Explorer │  │          │  │          │  │          │   │\n",
    "│  └──────────┘  └──────────┘  └──────────┘  └──────────┘   │\n",
    "└─────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "### Key Components:\n",
    "- **Bedrock Agents**: AI-powered agents that understand natural language and execute actions\n",
    "- **Lambda Functions**: Serverless compute that implements business logic\n",
    "- **Action Groups**: Collections of Lambda functions grouped by functionality\n",
    "- **AWS Services**: Native AWS services for data storage, monitoring, and cost analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mcp",
   "metadata": {},
   "source": [
    "## 2. What is MCP (Model Context Protocol)? <a name=\"mcp\"></a>\n",
    "\n",
    "MCP (Model Context Protocol) is a standardized protocol for sharing context between AI models and applications. In the context of AWS Bedrock:\n",
    "\n",
    "### Key Features of MCP:\n",
    "1. **Context Sharing**: Allows models to maintain conversation history and state\n",
    "2. **Tool Integration**: Enables models to call external tools and APIs\n",
    "3. **Security**: Provides secure context boundaries and access controls\n",
    "4. **Scalability**: Supports distributed agent architectures\n",
    "\n",
    "### MCP in AWS Bedrock:\n",
    "```python\n",
    "# Example MCP context structure for Bedrock\n",
    "mcp_context = {\n",
    "    \"session_id\": \"unique-session-id\",\n",
    "    \"user_context\": {\n",
    "        \"account_id\": \"123456789\",\n",
    "        \"permissions\": [\"read:costs\", \"write:recommendations\"]\n",
    "    },\n",
    "    \"conversation_history\": [\n",
    "        {\"role\": \"user\", \"content\": \"What are my highest costs?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Your highest costs are in EC2...\"}\n",
    "    ],\n",
    "    \"available_tools\": [\n",
    "        \"get_cost_data\",\n",
    "        \"analyze_usage\",\n",
    "        \"generate_recommendations\"\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedrock",
   "metadata": {},
   "source": [
    "## 3. AWS Bedrock Agents Overview <a name=\"bedrock\"></a>\n",
    "\n",
    "AWS Bedrock Agents are AI-powered assistants that can:\n",
    "- Understand natural language requests\n",
    "- Execute actions through Lambda functions\n",
    "- Maintain conversation context\n",
    "- Work with multiple foundation models\n",
    "\n",
    "### Supported Foundation Models:\n",
    "- **Anthropic Claude 3**: Advanced reasoning and analysis\n",
    "- **Amazon Titan**: Cost-effective general purpose\n",
    "- **AI21 Jurassic**: Specialized financial analysis\n",
    "\n",
    "### Agent Capabilities:\n",
    "1. **Natural Language Understanding**: Parse user queries\n",
    "2. **Action Execution**: Call Lambda functions based on intent\n",
    "3. **Context Management**: Remember previous interactions\n",
    "4. **Multi-turn Conversations**: Handle complex workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deployment",
   "metadata": {},
   "source": [
    "## 4. Step-by-Step AWS CLI Deployment <a name=\"deployment\"></a>\n",
    "\n",
    "### Prerequisites Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prereq-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install AWS CLI if not already installed\n",
    "!pip install awscli boto3\n",
    "\n",
    "# Configure AWS credentials\n",
    "import os\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "# Set your AWS region\n",
    "os.environ['AWS_DEFAULT_REGION'] = 'us-east-1'\n",
    "\n",
    "# Get current AWS account ID\n",
    "sts = boto3.client('sts')\n",
    "account_id = sts.get_caller_identity()['Account']\n",
    "print(f\"AWS Account ID: {account_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iam-setup",
   "metadata": {},
   "source": [
    "### Step 1: Create IAM Roles for Bedrock Agents and Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-iam-roles",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "iam = boto3.client('iam')\n",
    "\n",
    "# Create Bedrock Agent Role\n",
    "bedrock_trust_policy = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": {\n",
    "                \"Service\": \"bedrock.amazonaws.com\"\n",
    "            },\n",
    "            \"Action\": \"sts:AssumeRole\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "try:\n",
    "    response = iam.create_role(\n",
    "        RoleName='BedrockAgentRole',\n",
    "        AssumeRolePolicyDocument=json.dumps(bedrock_trust_policy),\n",
    "        Description='Role for Bedrock Agents'\n",
    "    )\n",
    "    print(f\"Created Bedrock Agent Role: {response['Role']['Arn']}\")\n",
    "except ClientError as e:\n",
    "    if e.response['Error']['Code'] == 'EntityAlreadyExists':\n",
    "        print(\"Bedrock Agent Role already exists\")\n",
    "    else:\n",
    "        raise\n",
    "\n",
    "# Attach necessary policies\n",
    "try:\n",
    "    iam.attach_role_policy(\n",
    "        RoleName='BedrockAgentRole',\n",
    "        PolicyArn='arn:aws:iam::aws:policy/service-role/AmazonBedrockAgentBedrockFoundationModelPolicy'\n",
    "    )\n",
    "    print(\"Attached Bedrock Foundation Model Policy\")\n",
    "except Exception as e:\n",
    "    print(f\"Policy may already be attached: {e}\")\n",
    "\n",
    "# Create Lambda execution role\n",
    "lambda_trust_policy = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": {\n",
    "                \"Service\": \"lambda.amazonaws.com\"\n",
    "            },\n",
    "            \"Action\": \"sts:AssumeRole\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "try:\n",
    "    response = iam.create_role(\n",
    "        RoleName='FinOpsLambdaRole',\n",
    "        AssumeRolePolicyDocument=json.dumps(lambda_trust_policy),\n",
    "        Description='Role for FinOps Lambda functions'\n",
    "    )\n",
    "    print(f\"Created Lambda Role: {response['Role']['Arn']}\")\n",
    "except ClientError as e:\n",
    "    if e.response['Error']['Code'] == 'EntityAlreadyExists':\n",
    "        print(\"Lambda Role already exists\")\n",
    "    else:\n",
    "        raise\n",
    "\n",
    "# Attach policies to Lambda role\n",
    "policies_to_attach = [\n",
    "    'arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole',\n",
    "    'arn:aws:iam::aws:policy/AWSCostExplorerReadOnlyAccess',\n",
    "    'arn:aws:iam::aws:policy/CloudWatchReadOnlyAccess'\n",
    "]\n",
    "\n",
    "for policy_arn in policies_to_attach:\n",
    "    try:\n",
    "        iam.attach_role_policy(\n",
    "            RoleName='FinOpsLambdaRole',\n",
    "            PolicyArn=policy_arn\n",
    "        )\n",
    "        print(f\"Attached policy: {policy_arn.split('/')[-1]}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Policy may already be attached: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s3-setup",
   "metadata": {},
   "source": [
    "### Step 2: Create S3 Bucket for Agent Instructions and Lambda Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-s3-bucket",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import time\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# Create unique bucket name\n",
    "bucket_name = f\"finops-bedrock-agents-{account_id}-{int(time.time())}\"\n",
    "\n",
    "try:\n",
    "    s3.create_bucket(Bucket=bucket_name)\n",
    "    print(f\"Created S3 bucket: {bucket_name}\")\n",
    "    \n",
    "    # Enable versioning\n",
    "    s3.put_bucket_versioning(\n",
    "        Bucket=bucket_name,\n",
    "        VersioningConfiguration={'Status': 'Enabled'}\n",
    "    )\n",
    "    print(\"Enabled bucket versioning\")\n",
    "    \n",
    "    # Store bucket name for later use\n",
    "    os.environ['FINOPS_BUCKET'] = bucket_name\n",
    "    \n",
    "except ClientError as e:\n",
    "    if e.response['Error']['Code'] == 'BucketAlreadyExists':\n",
    "        print(f\"Bucket {bucket_name} already exists\")\n",
    "    else:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lambda-deployment",
   "metadata": {},
   "source": [
    "## 5. Lambda Functions Implementation <a name=\"lambda\"></a>\n",
    "\n",
    "### Create Lambda Function Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-lambda-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "# Create directory for Lambda functions\n",
    "lambda_dir = 'lambda_functions'\n",
    "os.makedirs(lambda_dir, exist_ok=True)\n",
    "\n",
    "# Cost Analysis Lambda Function\n",
    "cost_analysis_code = '''import json\n",
    "import boto3\n",
    "from datetime import datetime, timedelta\n",
    "from decimal import Decimal\n",
    "\n",
    "ce_client = boto3.client('ce')  # Cost Explorer client\n",
    "cloudwatch = boto3.client('cloudwatch')\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    \"\"\"\n",
    "    Handles cost analysis requests from Bedrock agent\n",
    "    \"\"\"\n",
    "    print(f\"Received event: {json.dumps(event)}\")\n",
    "    \n",
    "    # Parse the action from Bedrock agent\n",
    "    action = event.get('actionGroup', '')\n",
    "    function = event.get('function', '')\n",
    "    parameters = event.get('parameters', [])\n",
    "    \n",
    "    # Convert parameters list to dict\n",
    "    params = {}\n",
    "    for param in parameters:\n",
    "        params[param.get('name', '')] = param.get('value', '')\n",
    "    \n",
    "    try:\n",
    "        if function == 'get_cost_breakdown':\n",
    "            result = get_cost_breakdown(params)\n",
    "        elif function == 'analyze_cost_trends':\n",
    "            result = analyze_cost_trends(params)\n",
    "        elif function == 'identify_cost_anomalies':\n",
    "            result = identify_cost_anomalies(params)\n",
    "        else:\n",
    "            result = {\n",
    "                'error': f'Unknown function: {function}'\n",
    "            }\n",
    "        \n",
    "        return {\n",
    "            'response': result\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        return {\n",
    "            'response': {\n",
    "                'error': str(e)\n",
    "            }\n",
    "        }\n",
    "\n",
    "def get_cost_breakdown(params):\n",
    "    \"\"\"\n",
    "    Get cost breakdown by service\n",
    "    \"\"\"\n",
    "    days = int(params.get('days', '7'))\n",
    "    end_date = datetime.now().date()\n",
    "    start_date = end_date - timedelta(days=days)\n",
    "    \n",
    "    try:\n",
    "        response = ce_client.get_cost_and_usage(\n",
    "            TimePeriod={\n",
    "                'Start': start_date.strftime('%Y-%m-%d'),\n",
    "                'End': end_date.strftime('%Y-%m-%d')\n",
    "            },\n",
    "            Granularity='DAILY',\n",
    "            Metrics=['UnblendedCost'],\n",
    "            GroupBy=[\n",
    "                {\n",
    "                    'Type': 'DIMENSION',\n",
    "                    'Key': 'SERVICE'\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # Process results\n",
    "        cost_by_service = {}\n",
    "        for result in response['ResultsByTime']:\n",
    "            for group in result['Groups']:\n",
    "                service = group['Keys'][0]\n",
    "                cost = float(group['Metrics']['UnblendedCost']['Amount'])\n",
    "                if service not in cost_by_service:\n",
    "                    cost_by_service[service] = 0\n",
    "                cost_by_service[service] += cost\n",
    "        \n",
    "        # Sort by cost\n",
    "        sorted_costs = sorted(\n",
    "            cost_by_service.items(), \n",
    "            key=lambda x: x[1], \n",
    "            reverse=True\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'period': f'{days} days',\n",
    "            'total_cost': sum(cost_by_service.values()),\n",
    "            'cost_by_service': dict(sorted_costs[:10])  # Top 10 services\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'error': f'Failed to get cost breakdown: {str(e)}'\n",
    "        }\n",
    "\n",
    "def analyze_cost_trends(params):\n",
    "    \"\"\"\n",
    "    Analyze cost trends and predict future costs\n",
    "    \"\"\"\n",
    "    days = int(params.get('days', '30'))\n",
    "    service = params.get('service', None)\n",
    "    \n",
    "    end_date = datetime.now().date()\n",
    "    start_date = end_date - timedelta(days=days)\n",
    "    \n",
    "    try:\n",
    "        # Build query parameters\n",
    "        query_params = {\n",
    "            'TimePeriod': {\n",
    "                'Start': start_date.strftime('%Y-%m-%d'),\n",
    "                'End': end_date.strftime('%Y-%m-%d')\n",
    "            },\n",
    "            'Granularity': 'DAILY',\n",
    "            'Metrics': ['UnblendedCost']\n",
    "        }\n",
    "        \n",
    "        if service:\n",
    "            query_params['Filter'] = {\n",
    "                'Dimensions': {\n",
    "                    'Key': 'SERVICE',\n",
    "                    'Values': [service]\n",
    "                }\n",
    "            }\n",
    "        \n",
    "        response = ce_client.get_cost_and_usage(**query_params)\n",
    "        \n",
    "        # Extract daily costs\n",
    "        daily_costs = []\n",
    "        for result in response['ResultsByTime']:\n",
    "            date = result['TimePeriod']['Start']\n",
    "            cost = float(result['Total']['UnblendedCost']['Amount'])\n",
    "            daily_costs.append({\n",
    "                'date': date,\n",
    "                'cost': cost\n",
    "            })\n",
    "        \n",
    "        # Calculate trend\n",
    "        if len(daily_costs) > 1:\n",
    "            first_week_avg = sum(d['cost'] for d in daily_costs[:7]) / 7\n",
    "            last_week_avg = sum(d['cost'] for d in daily_costs[-7:]) / 7\n",
    "            trend_percentage = ((last_week_avg - first_week_avg) / first_week_avg) * 100\n",
    "        else:\n",
    "            trend_percentage = 0\n",
    "        \n",
    "        return {\n",
    "            'period': f'{days} days',\n",
    "            'service': service or 'All Services',\n",
    "            'daily_costs': daily_costs,\n",
    "            'trend': {\n",
    "                'percentage': round(trend_percentage, 2),\n",
    "                'direction': 'increasing' if trend_percentage > 0 else 'decreasing'\n",
    "            },\n",
    "            'average_daily_cost': sum(d['cost'] for d in daily_costs) / len(daily_costs)\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'error': f'Failed to analyze trends: {str(e)}'\n",
    "        }\n",
    "\n",
    "def identify_cost_anomalies(params):\n",
    "    \"\"\"\n",
    "    Identify unusual spikes or drops in costs\n",
    "    \"\"\"\n",
    "    threshold = float(params.get('threshold', '20'))  # 20% change threshold\n",
    "    \n",
    "    end_date = datetime.now().date()\n",
    "    start_date = end_date - timedelta(days=30)\n",
    "    \n",
    "    try:\n",
    "        response = ce_client.get_cost_and_usage(\n",
    "            TimePeriod={\n",
    "                'Start': start_date.strftime('%Y-%m-%d'),\n",
    "                'End': end_date.strftime('%Y-%m-%d')\n",
    "            },\n",
    "            Granularity='DAILY',\n",
    "            Metrics=['UnblendedCost']\n",
    "        )\n",
    "        \n",
    "        # Analyze daily costs for anomalies\n",
    "        daily_costs = []\n",
    "        for result in response['ResultsByTime']:\n",
    "            cost = float(result['Total']['UnblendedCost']['Amount'])\n",
    "            daily_costs.append(cost)\n",
    "        \n",
    "        # Calculate average and standard deviation\n",
    "        avg_cost = sum(daily_costs) / len(daily_costs)\n",
    "        \n",
    "        anomalies = []\n",
    "        for i, cost in enumerate(daily_costs):\n",
    "            deviation = ((cost - avg_cost) / avg_cost) * 100\n",
    "            if abs(deviation) > threshold:\n",
    "                anomalies.append({\n",
    "                    'date': (start_date + timedelta(days=i)).strftime('%Y-%m-%d'),\n",
    "                    'cost': cost,\n",
    "                    'deviation_percentage': round(deviation, 2),\n",
    "                    'type': 'spike' if deviation > 0 else 'drop'\n",
    "                })\n",
    "        \n",
    "        return {\n",
    "            'anomalies_found': len(anomalies),\n",
    "            'threshold_used': threshold,\n",
    "            'average_daily_cost': avg_cost,\n",
    "            'anomalies': anomalies\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'error': f'Failed to identify anomalies: {str(e)}'\n",
    "        }\n",
    "'''\n",
    "\n",
    "# Write Lambda function to file\n",
    "with open(os.path.join(lambda_dir, 'cost_analysis_lambda.py'), 'w') as f:\n",
    "    f.write(cost_analysis_code)\n",
    "\n",
    "print(\"Created cost_analysis_lambda.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-optimization-lambda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resource Optimization Lambda Function\n",
    "optimization_code = '''import json\n",
    "import boto3\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "ec2_client = boto3.client('ec2')\n",
    "cloudwatch = boto3.client('cloudwatch')\n",
    "rds_client = boto3.client('rds')\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    \"\"\"\n",
    "    Handles resource optimization requests from Bedrock agent\n",
    "    \"\"\"\n",
    "    print(f\"Received event: {json.dumps(event)}\")\n",
    "    \n",
    "    function = event.get('function', '')\n",
    "    parameters = event.get('parameters', [])\n",
    "    \n",
    "    # Convert parameters list to dict\n",
    "    params = {}\n",
    "    for param in parameters:\n",
    "        params[param.get('name', '')] = param.get('value', '')\n",
    "    \n",
    "    try:\n",
    "        if function == 'get_optimization_recommendations':\n",
    "            result = get_optimization_recommendations(params)\n",
    "        elif function == 'analyze_resource_utilization':\n",
    "            result = analyze_resource_utilization(params)\n",
    "        elif function == 'identify_idle_resources':\n",
    "            result = identify_idle_resources(params)\n",
    "        else:\n",
    "            result = {'error': f'Unknown function: {function}'}\n",
    "        \n",
    "        return {'response': result}\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        return {'response': {'error': str(e)}}\n",
    "\n",
    "def get_optimization_recommendations(params):\n",
    "    \"\"\"\n",
    "    Get comprehensive optimization recommendations\n",
    "    \"\"\"\n",
    "    resource_type = params.get('resource_type', 'all')\n",
    "    recommendations = []\n",
    "    \n",
    "    # Get EC2 recommendations\n",
    "    if resource_type in ['all', 'ec2']:\n",
    "        ec2_recs = get_ec2_recommendations()\n",
    "        recommendations.extend(ec2_recs)\n",
    "    \n",
    "    # Get RDS recommendations\n",
    "    if resource_type in ['all', 'rds']:\n",
    "        rds_recs = get_rds_recommendations()\n",
    "        recommendations.extend(rds_recs)\n",
    "    \n",
    "    # Calculate total savings\n",
    "    total_savings = sum(rec.get('estimated_monthly_savings', 0) for rec in recommendations)\n",
    "    \n",
    "    return {\n",
    "        'total_recommendations': len(recommendations),\n",
    "        'total_estimated_monthly_savings': total_savings,\n",
    "        'recommendations': recommendations\n",
    "    }\n",
    "\n",
    "def get_ec2_recommendations():\n",
    "    \"\"\"\n",
    "    Get EC2 optimization recommendations\n",
    "    \"\"\"\n",
    "    recommendations = []\n",
    "    \n",
    "    try:\n",
    "        # Get all running instances\n",
    "        response = ec2_client.describe_instances(\n",
    "            Filters=[{'Name': 'instance-state-name', 'Values': ['running']}]\n",
    "        )\n",
    "        \n",
    "        for reservation in response['Reservations']:\n",
    "            for instance in reservation['Instances']:\n",
    "                instance_id = instance['InstanceId']\n",
    "                instance_type = instance['InstanceType']\n",
    "                \n",
    "                # Get CPU utilization\n",
    "                cpu_stats = get_instance_cpu_utilization(instance_id)\n",
    "                \n",
    "                if cpu_stats['average'] < 10:\n",
    "                    recommendations.append({\n",
    "                        'resource_type': 'EC2',\n",
    "                        'resource_id': instance_id,\n",
    "                        'current_type': instance_type,\n",
    "                        'recommendation': 'Terminate or stop instance',\n",
    "                        'reason': f\"Low CPU utilization: {cpu_stats['average']:.1f}%\",\n",
    "                        'estimated_monthly_savings': estimate_instance_cost(instance_type),\n",
    "                        'priority': 'high'\n",
    "                    })\n",
    "                elif cpu_stats['average'] < 40:\n",
    "                    recommendations.append({\n",
    "                        'resource_type': 'EC2',\n",
    "                        'resource_id': instance_id,\n",
    "                        'current_type': instance_type,\n",
    "                        'recommendation': 'Consider downsizing instance',\n",
    "                        'reason': f\"Moderate CPU utilization: {cpu_stats['average']:.1f}%\",\n",
    "                        'estimated_monthly_savings': estimate_instance_cost(instance_type) * 0.3,\n",
    "                        'priority': 'medium'\n",
    "                    })\n",
    "                    \n",
    "    except Exception as e:\n",
    "        print(f\"Error getting EC2 recommendations: {e}\")\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "def get_instance_cpu_utilization(instance_id, days=7):\n",
    "    \"\"\"\n",
    "    Get CPU utilization statistics for an EC2 instance\n",
    "    \"\"\"\n",
    "    end_time = datetime.now()\n",
    "    start_time = end_time - timedelta(days=days)\n",
    "    \n",
    "    try:\n",
    "        response = cloudwatch.get_metric_statistics(\n",
    "            Namespace='AWS/EC2',\n",
    "            MetricName='CPUUtilization',\n",
    "            Dimensions=[{'Name': 'InstanceId', 'Value': instance_id}],\n",
    "            StartTime=start_time,\n",
    "            EndTime=end_time,\n",
    "            Period=3600,\n",
    "            Statistics=['Average', 'Maximum']\n",
    "        )\n",
    "        \n",
    "        datapoints = response.get('Datapoints', [])\n",
    "        if datapoints:\n",
    "            avg_cpu = sum(d['Average'] for d in datapoints) / len(datapoints)\n",
    "            max_cpu = max(d['Maximum'] for d in datapoints)\n",
    "            return {'average': avg_cpu, 'maximum': max_cpu}\n",
    "        else:\n",
    "            return {'average': 0, 'maximum': 0}\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error getting CPU stats: {e}\")\n",
    "        return {'average': 0, 'maximum': 0}\n",
    "\n",
    "def estimate_instance_cost(instance_type):\n",
    "    \"\"\"\n",
    "    Estimate monthly cost for an instance type\n",
    "    \"\"\"\n",
    "    # Simplified cost estimation (in production, use AWS Pricing API)\n",
    "    cost_map = {\n",
    "        't2.micro': 8.5, 't2.small': 17, 't2.medium': 34,\n",
    "        't3.micro': 7.6, 't3.small': 15.2, 't3.medium': 30.4,\n",
    "        'm5.large': 70, 'm5.xlarge': 140,\n",
    "        'c5.large': 62, 'c5.xlarge': 124\n",
    "    }\n",
    "    return cost_map.get(instance_type, 50)\n",
    "\n",
    "def get_rds_recommendations():\n",
    "    \"\"\"\n",
    "    Get RDS optimization recommendations\n",
    "    \"\"\"\n",
    "    recommendations = []\n",
    "    \n",
    "    try:\n",
    "        response = rds_client.describe_db_instances()\n",
    "        \n",
    "        for db in response['DBInstances']:\n",
    "            db_id = db['DBInstanceIdentifier']\n",
    "            \n",
    "            # Check if Multi-AZ is needed for non-production\n",
    "            if db['MultiAZ']:\n",
    "                # Check tags to determine if production\n",
    "                tags = rds_client.list_tags_for_resource(\n",
    "                    ResourceName=db['DBInstanceArn']\n",
    "                )['TagList']\n",
    "                \n",
    "                is_prod = any(tag['Key'] == 'Environment' and \n",
    "                             tag['Value'].lower() == 'production' \n",
    "                             for tag in tags)\n",
    "                \n",
    "                if not is_prod:\n",
    "                    recommendations.append({\n",
    "                        'resource_type': 'RDS',\n",
    "                        'resource_id': db_id,\n",
    "                        'recommendation': 'Disable Multi-AZ',\n",
    "                        'reason': 'Non-production database with Multi-AZ enabled',\n",
    "                        'estimated_monthly_savings': estimate_rds_cost(db) / 2,\n",
    "                        'priority': 'high'\n",
    "                    })\n",
    "                    \n",
    "    except Exception as e:\n",
    "        print(f\"Error getting RDS recommendations: {e}\")\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "def estimate_rds_cost(db_instance):\n",
    "    \"\"\"\n",
    "    Estimate RDS monthly cost\n",
    "    \"\"\"\n",
    "    instance_class = db_instance['DBInstanceClass']\n",
    "    cost_map = {\n",
    "        'db.t3.micro': 15, 'db.t3.small': 30, 'db.t3.medium': 60,\n",
    "        'db.m5.large': 140, 'db.m5.xlarge': 280\n",
    "    }\n",
    "    return cost_map.get(instance_class, 100)\n",
    "\n",
    "def identify_idle_resources(params):\n",
    "    \"\"\"\n",
    "    Identify idle resources across services\n",
    "    \"\"\"\n",
    "    idle_resources = []\n",
    "    \n",
    "    # Check EC2 instances\n",
    "    try:\n",
    "        response = ec2_client.describe_instances(\n",
    "            Filters=[{'Name': 'instance-state-name', 'Values': ['running']}]\n",
    "        )\n",
    "        \n",
    "        for reservation in response['Reservations']:\n",
    "            for instance in reservation['Instances']:\n",
    "                instance_id = instance['InstanceId']\n",
    "                cpu_stats = get_instance_cpu_utilization(instance_id)\n",
    "                \n",
    "                if cpu_stats['average'] < 5:\n",
    "                    idle_resources.append({\n",
    "                        'resource_type': 'EC2',\n",
    "                        'resource_id': instance_id,\n",
    "                        'status': 'idle',\n",
    "                        'details': f\"CPU usage: {cpu_stats['average']:.1f}%\",\n",
    "                        'recommended_action': 'Terminate or stop'\n",
    "                    })\n",
    "                    \n",
    "    except Exception as e:\n",
    "        print(f\"Error checking idle EC2: {e}\")\n",
    "    \n",
    "    return {\n",
    "        'total_idle_resources': len(idle_resources),\n",
    "        'resources': idle_resources\n",
    "    }\n",
    "'''\n",
    "\n",
    "# Write Lambda function to file\n",
    "with open(os.path.join(lambda_dir, 'optimization_lambda.py'), 'w') as f:\n",
    "    f.write(optimization_code)\n",
    "\n",
    "print(\"Created optimization_lambda.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-forecasting-lambda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecasting Lambda Function\n",
    "forecasting_code = '''import json\n",
    "import boto3\n",
    "from datetime import datetime, timedelta\n",
    "import statistics\n",
    "\n",
    "ce_client = boto3.client('ce')\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    \"\"\"\n",
    "    Handles cost forecasting requests from Bedrock agent\n",
    "    \"\"\"\n",
    "    print(f\"Received event: {json.dumps(event)}\")\n",
    "    \n",
    "    function = event.get('function', '')\n",
    "    parameters = event.get('parameters', [])\n",
    "    \n",
    "    # Convert parameters list to dict\n",
    "    params = {}\n",
    "    for param in parameters:\n",
    "        params[param.get('name', '')] = param.get('value', '')\n",
    "    \n",
    "    try:\n",
    "        if function == 'forecast_costs':\n",
    "            result = forecast_costs(params)\n",
    "        elif function == 'analyze_growth_trends':\n",
    "            result = analyze_growth_trends(params)\n",
    "        elif function == 'set_budget_alerts':\n",
    "            result = set_budget_alerts(params)\n",
    "        else:\n",
    "            result = {'error': f'Unknown function: {function}'}\n",
    "        \n",
    "        return {'response': result}\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        return {'response': {'error': str(e)}}\n",
    "\n",
    "def forecast_costs(params):\n",
    "    \"\"\"\n",
    "    Forecast future costs based on historical data\n",
    "    \"\"\"\n",
    "    months_to_forecast = int(params.get('months', '3'))\n",
    "    \n",
    "    # Get historical data (6 months)\n",
    "    end_date = datetime.now().date()\n",
    "    start_date = end_date - timedelta(days=180)\n",
    "    \n",
    "    try:\n",
    "        response = ce_client.get_cost_and_usage(\n",
    "            TimePeriod={\n",
    "                'Start': start_date.strftime('%Y-%m-%d'),\n",
    "                'End': end_date.strftime('%Y-%m-%d')\n",
    "            },\n",
    "            Granularity='MONTHLY',\n",
    "            Metrics=['UnblendedCost']\n",
    "        )\n",
    "        \n",
    "        # Extract monthly costs\n",
    "        monthly_costs = []\n",
    "        for result in response['ResultsByTime']:\n",
    "            cost = float(result['Total']['UnblendedCost']['Amount'])\n",
    "            monthly_costs.append(cost)\n",
    "        \n",
    "        # Calculate growth rate\n",
    "        if len(monthly_costs) >= 2:\n",
    "            growth_rates = []\n",
    "            for i in range(1, len(monthly_costs)):\n",
    "                if monthly_costs[i-1] > 0:\n",
    "                    rate = (monthly_costs[i] - monthly_costs[i-1]) / monthly_costs[i-1]\n",
    "                    growth_rates.append(rate)\n",
    "            \n",
    "            avg_growth_rate = statistics.mean(growth_rates) if growth_rates else 0\n",
    "        else:\n",
    "            avg_growth_rate = 0\n",
    "        \n",
    "        # Generate forecasts\n",
    "        current_cost = monthly_costs[-1] if monthly_costs else 0\n",
    "        forecasts = []\n",
    "        \n",
    "        for month in range(1, months_to_forecast + 1):\n",
    "            forecasted_cost = current_cost * ((1 + avg_growth_rate) ** month)\n",
    "            \n",
    "            # Calculate confidence based on historical variance\n",
    "            if len(monthly_costs) > 2:\n",
    "                cost_variance = statistics.stdev(monthly_costs) / statistics.mean(monthly_costs)\n",
    "                confidence = max(0.5, 1 - (cost_variance * month * 0.1))\n",
    "            else:\n",
    "                confidence = 0.7\n",
    "            \n",
    "            forecasts.append({\n",
    "                'month': month,\n",
    "                'predicted_cost': round(forecasted_cost, 2),\n",
    "                'confidence': round(confidence, 2),\n",
    "                'date': (end_date + timedelta(days=30*month)).strftime('%Y-%m')\n",
    "            })\n",
    "        \n",
    "        return {\n",
    "            'forecast_period': f'{months_to_forecast} months',\n",
    "            'current_monthly_cost': round(current_cost, 2),\n",
    "            'average_growth_rate': f'{avg_growth_rate*100:.1f}%',\n",
    "            'forecasts': forecasts,\n",
    "            'historical_data_points': len(monthly_costs)\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {'error': f'Failed to forecast costs: {str(e)}'}\n",
    "\n",
    "def analyze_growth_trends(params):\n",
    "    \"\"\"\n",
    "    Analyze resource growth trends\n",
    "    \"\"\"\n",
    "    service = params.get('service', None)\n",
    "    \n",
    "    end_date = datetime.now().date()\n",
    "    start_date = end_date - timedelta(days=90)\n",
    "    \n",
    "    try:\n",
    "        query_params = {\n",
    "            'TimePeriod': {\n",
    "                'Start': start_date.strftime('%Y-%m-%d'),\n",
    "                'End': end_date.strftime('%Y-%m-%d')\n",
    "            },\n",
    "            'Granularity': 'MONTHLY',\n",
    "            'Metrics': ['UnblendedCost'],\n",
    "            'GroupBy': [{'Type': 'DIMENSION', 'Key': 'SERVICE'}]\n",
    "        }\n",
    "        \n",
    "        response = ce_client.get_cost_and_usage(**query_params)\n",
    "        \n",
    "        # Analyze growth by service\n",
    "        service_trends = {}\n",
    "        \n",
    "        for result in response['ResultsByTime']:\n",
    "            for group in result['Groups']:\n",
    "                svc = group['Keys'][0]\n",
    "                cost = float(group['Metrics']['UnblendedCost']['Amount'])\n",
    "                \n",
    "                if svc not in service_trends:\n",
    "                    service_trends[svc] = []\n",
    "                service_trends[svc].append(cost)\n",
    "        \n",
    "        # Calculate growth rates\n",
    "        growth_analysis = []\n",
    "        for svc, costs in service_trends.items():\n",
    "            if len(costs) >= 2 and costs[0] > 0:\n",
    "                growth_rate = ((costs[-1] - costs[0]) / costs[0]) * 100\n",
    "                growth_analysis.append({\n",
    "                    'service': svc,\n",
    "                    'initial_cost': round(costs[0], 2),\n",
    "                    'current_cost': round(costs[-1], 2),\n",
    "                    'growth_percentage': round(growth_rate, 1),\n",
    "                    'trend': 'increasing' if growth_rate > 0 else 'decreasing'\n",
    "                })\n",
    "        \n",
    "        # Sort by growth rate\n",
    "        growth_analysis.sort(key=lambda x: x['growth_percentage'], reverse=True)\n",
    "        \n",
    "        return {\n",
    "            'analysis_period': '3 months',\n",
    "            'top_growing_services': growth_analysis[:5],\n",
    "            'declining_services': [s for s in growth_analysis if s['growth_percentage'] < 0][:5]\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {'error': f'Failed to analyze growth trends: {str(e)}'}\n",
    "\n",
    "def set_budget_alerts(params):\n",
    "    \"\"\"\n",
    "    Set up budget alerts (simulation)\n",
    "    \"\"\"\n",
    "    budget_amount = float(params.get('amount', '10000'))\n",
    "    alert_threshold = int(params.get('threshold', '80'))\n",
    "    \n",
    "    # In production, this would use AWS Budgets API\n",
    "    # For demo, we'll return a simulated response\n",
    "    \n",
    "    return {\n",
    "        'budget_created': True,\n",
    "        'budget_details': {\n",
    "            'name': 'FinOps-Monthly-Budget',\n",
    "            'amount': budget_amount,\n",
    "            'currency': 'USD',\n",
    "            'time_period': 'MONTHLY',\n",
    "            'alerts': [\n",
    "                {\n",
    "                    'threshold': alert_threshold,\n",
    "                    'type': 'PERCENTAGE',\n",
    "                    'notification': 'email'\n",
    "                },\n",
    "                {\n",
    "                    'threshold': 100,\n",
    "                    'type': 'PERCENTAGE',\n",
    "                    'notification': 'email'\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        'message': f'Budget alerts will trigger at {alert_threshold}% and 100% of ${budget_amount}'\n",
    "    }\n",
    "'''\n",
    "\n",
    "# Write Lambda function to file\n",
    "with open(os.path.join(lambda_dir, 'forecasting_lambda.py'), 'w') as f:\n",
    "    f.write(forecasting_code)\n",
    "\n",
    "print(\"Created forecasting_lambda.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "package-deploy-lambda",
   "metadata": {},
   "source": [
    "### Package and Deploy Lambda Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "package-lambdas",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import boto3\n",
    "import time\n",
    "\n",
    "lambda_client = boto3.client('lambda')\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# Package Lambda functions\n",
    "lambda_functions = [\n",
    "    {\n",
    "        'name': 'finops-cost-analysis',\n",
    "        'file': 'cost_analysis_lambda.py',\n",
    "        'handler': 'cost_analysis_lambda.lambda_handler'\n",
    "    },\n",
    "    {\n",
    "        'name': 'finops-optimization',\n",
    "        'file': 'optimization_lambda.py',\n",
    "        'handler': 'optimization_lambda.lambda_handler'\n",
    "    },\n",
    "    {\n",
    "        'name': 'finops-forecasting',\n",
    "        'file': 'forecasting_lambda.py',\n",
    "        'handler': 'forecasting_lambda.lambda_handler'\n",
    "    }\n",
    "]\n",
    "\n",
    "deployed_functions = {}\n",
    "\n",
    "for func in lambda_functions:\n",
    "    # Create zip file\n",
    "    zip_filename = f\"{func['name']}.zip\"\n",
    "    with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "        zipf.write(os.path.join(lambda_dir, func['file']), func['file'])\n",
    "    \n",
    "    # Upload to S3\n",
    "    s3_key = f\"lambda-functions/{zip_filename}\"\n",
    "    s3.upload_file(zip_filename, os.environ['FINOPS_BUCKET'], s3_key)\n",
    "    print(f\"Uploaded {zip_filename} to S3\")\n",
    "    \n",
    "    # Deploy Lambda function\n",
    "    try:\n",
    "        response = lambda_client.create_function(\n",
    "            FunctionName=func['name'],\n",
    "            Runtime='python3.9',\n",
    "            Role=f\"arn:aws:iam::{account_id}:role/FinOpsLambdaRole\",\n",
    "            Handler=func['handler'],\n",
    "            Code={\n",
    "                'S3Bucket': os.environ['FINOPS_BUCKET'],\n",
    "                'S3Key': s3_key\n",
    "            },\n",
    "            Timeout=60,\n",
    "            MemorySize=256,\n",
    "            Description=f'FinOps {func[\"name\"]} function'\n",
    "        )\n",
    "        deployed_functions[func['name']] = response['FunctionArn']\n",
    "        print(f\"Deployed Lambda: {func['name']}\")\n",
    "        \n",
    "    except lambda_client.exceptions.ResourceConflictException:\n",
    "        # Function already exists, update it\n",
    "        response = lambda_client.update_function_code(\n",
    "            FunctionName=func['name'],\n",
    "            S3Bucket=os.environ['FINOPS_BUCKET'],\n",
    "            S3Key=s3_key\n",
    "        )\n",
    "        deployed_functions[func['name']] = response['FunctionArn']\n",
    "        print(f\"Updated Lambda: {func['name']}\")\n",
    "    \n",
    "    # Clean up zip file\n",
    "    os.remove(zip_filename)\n",
    "    time.sleep(2)  # Small delay to avoid rate limits\n",
    "\n",
    "print(\"\\nDeployed Lambda functions:\")\n",
    "for name, arn in deployed_functions.items():\n",
    "    print(f\"  {name}: {arn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agent-deployment",
   "metadata": {},
   "source": [
    "## 6. AI Agent Code and Action Groups <a name=\"agents\"></a>\n",
    "\n",
    "### Create Bedrock Agents with Action Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-api-schemas",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create API schemas for action groups\n",
    "import json\n",
    "\n",
    "# Cost Analysis API Schema\n",
    "cost_analysis_api_schema = {\n",
    "    \"openapi\": \"3.0.0\",\n",
    "    \"info\": {\n",
    "        \"title\": \"Cost Analysis API\",\n",
    "        \"version\": \"1.0.0\",\n",
    "        \"description\": \"API for analyzing AWS costs\"\n",
    "    },\n",
    "    \"paths\": {\n",
    "        \"/get_cost_breakdown\": {\n",
    "            \"post\": {\n",
    "                \"summary\": \"Get cost breakdown by service\",\n",
    "                \"description\": \"Returns breakdown of AWS costs by service for specified time period\",\n",
    "                \"operationId\": \"getCostBreakdown\",\n",
    "                \"requestBody\": {\n",
    "                    \"content\": {\n",
    "                        \"application/json\": {\n",
    "                            \"schema\": {\n",
    "                                \"type\": \"object\",\n",
    "                                \"properties\": {\n",
    "                                    \"days\": {\n",
    "                                        \"type\": \"integer\",\n",
    "                                        \"description\": \"Number of days to analyze\",\n",
    "                                        \"default\": 7\n",
    "                                    }\n",
    "                                }\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "                \"responses\": {\n",
    "                    \"200\": {\n",
    "                        \"description\": \"Cost breakdown retrieved successfully\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"/analyze_cost_trends\": {\n",
    "            \"post\": {\n",
    "                \"summary\": \"Analyze cost trends\",\n",
    "                \"description\": \"Analyze cost trends over time and identify patterns\",\n",
    "                \"operationId\": \"analyzeCostTrends\",\n",
    "                \"requestBody\": {\n",
    "                    \"content\": {\n",
    "                        \"application/json\": {\n",
    "                            \"schema\": {\n",
    "                                \"type\": \"object\",\n",
    "                                \"properties\": {\n",
    "                                    \"days\": {\n",
    "                                        \"type\": \"integer\",\n",
    "                                        \"default\": 30\n",
    "                                    },\n",
    "                                    \"service\": {\n",
    "                                        \"type\": \"string\",\n",
    "                                        \"description\": \"Specific service to analyze\"\n",
    "                                    }\n",
    "                                }\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "                \"responses\": {\n",
    "                    \"200\": {\n",
    "                        \"description\": \"Trend analysis completed\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"/identify_cost_anomalies\": {\n",
    "            \"post\": {\n",
    "                \"summary\": \"Identify cost anomalies\",\n",
    "                \"description\": \"Find unusual spikes or drops in costs\",\n",
    "                \"operationId\": \"identifyCostAnomalies\",\n",
    "                \"requestBody\": {\n",
    "                    \"content\": {\n",
    "                        \"application/json\": {\n",
    "                            \"schema\": {\n",
    "                                \"type\": \"object\",\n",
    "                                \"properties\": {\n",
    "                                    \"threshold\": {\n",
    "                                        \"type\": \"number\",\n",
    "                                        \"default\": 20\n",
    "                                    }\n",
    "                                }\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "                \"responses\": {\n",
    "                    \"200\": {\n",
    "                        \"description\": \"Anomalies identified\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save to S3\n",
    "s3.put_object(\n",
    "    Bucket=os.environ['FINOPS_BUCKET'],\n",
    "    Key='api-schemas/cost-analysis-api.json',\n",
    "    Body=json.dumps(cost_analysis_api_schema)\n",
    ")\n",
    "\n",
    "print(\"Created Cost Analysis API schema\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-optimization-schema",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization API Schema\n",
    "optimization_api_schema = {\n",
    "    \"openapi\": \"3.0.0\",\n",
    "    \"info\": {\n",
    "        \"title\": \"Resource Optimization API\",\n",
    "        \"version\": \"1.0.0\"\n",
    "    },\n",
    "    \"paths\": {\n",
    "        \"/get_optimization_recommendations\": {\n",
    "            \"post\": {\n",
    "                \"summary\": \"Get resource optimization recommendations\",\n",
    "                \"operationId\": \"getOptimizationRecommendations\",\n",
    "                \"requestBody\": {\n",
    "                    \"content\": {\n",
    "                        \"application/json\": {\n",
    "                            \"schema\": {\n",
    "                                \"type\": \"object\",\n",
    "                                \"properties\": {\n",
    "                                    \"resource_type\": {\n",
    "                                        \"type\": \"string\",\n",
    "                                        \"enum\": [\"ec2\", \"rds\", \"s3\", \"all\"],\n",
    "                                        \"default\": \"all\"\n",
    "                                    }\n",
    "                                }\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "                \"responses\": {\n",
    "                    \"200\": {\n",
    "                        \"description\": \"Recommendations retrieved\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"/identify_idle_resources\": {\n",
    "            \"post\": {\n",
    "                \"summary\": \"Identify idle resources\",\n",
    "                \"operationId\": \"identifyIdleResources\",\n",
    "                \"responses\": {\n",
    "                    \"200\": {\n",
    "                        \"description\": \"Idle resources identified\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Forecasting API Schema\n",
    "forecasting_api_schema = {\n",
    "    \"openapi\": \"3.0.0\",\n",
    "    \"info\": {\n",
    "        \"title\": \"Cost Forecasting API\",\n",
    "        \"version\": \"1.0.0\"\n",
    "    },\n",
    "    \"paths\": {\n",
    "        \"/forecast_costs\": {\n",
    "            \"post\": {\n",
    "                \"summary\": \"Forecast future costs\",\n",
    "                \"operationId\": \"forecastCosts\",\n",
    "                \"requestBody\": {\n",
    "                    \"content\": {\n",
    "                        \"application/json\": {\n",
    "                            \"schema\": {\n",
    "                                \"type\": \"object\",\n",
    "                                \"properties\": {\n",
    "                                    \"months\": {\n",
    "                                        \"type\": \"integer\",\n",
    "                                        \"default\": 3\n",
    "                                    }\n",
    "                                }\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "                \"responses\": {\n",
    "                    \"200\": {\n",
    "                        \"description\": \"Forecast generated\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"/analyze_growth_trends\": {\n",
    "            \"post\": {\n",
    "                \"summary\": \"Analyze growth trends\",\n",
    "                \"operationId\": \"analyzeGrowthTrends\",\n",
    "                \"requestBody\": {\n",
    "                    \"content\": {\n",
    "                        \"application/json\": {\n",
    "                            \"schema\": {\n",
    "                                \"type\": \"object\",\n",
    "                                \"properties\": {\n",
    "                                    \"service\": {\n",
    "                                        \"type\": \"string\"\n",
    "                                    }\n",
    "                                }\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "                \"responses\": {\n",
    "                    \"200\": {\n",
    "                        \"description\": \"Growth trends analyzed\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save schemas to S3\n",
    "s3.put_object(\n",
    "    Bucket=os.environ['FINOPS_BUCKET'],\n",
    "    Key='api-schemas/optimization-api.json',\n",
    "    Body=json.dumps(optimization_api_schema)\n",
    ")\n",
    "\n",
    "s3.put_object(\n",
    "    Bucket=os.environ['FINOPS_BUCKET'],\n",
    "    Key='api-schemas/forecasting-api.json',\n",
    "    Body=json.dumps(forecasting_api_schema)\n",
    ")\n",
    "\n",
    "print(\"Created Optimization and Forecasting API schemas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-bedrock-agents",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import time\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "bedrock_agent = boto3.client('bedrock-agent')\n",
    "\n",
    "# Agent instructions\n",
    "agent_instructions = {\n",
    "    'cost_analyzer': '''You are a FinOps Cost Analysis specialist AI assistant. Your primary role is to help users understand their AWS costs.\n",
    "\n",
    "Your capabilities include:\n",
    "1. Analyzing AWS costs by service, region, and time period\n",
    "2. Identifying cost trends and patterns\n",
    "3. Detecting cost anomalies and unusual spending\n",
    "4. Providing detailed breakdowns of cloud expenses\n",
    "\n",
    "When users ask about costs:\n",
    "- Always provide specific numbers and percentages\n",
    "- Identify the top cost drivers\n",
    "- Compare current costs to historical data when relevant\n",
    "- Highlight any concerning trends or anomalies\n",
    "\n",
    "Use the available functions to fetch real-time cost data and provide accurate insights.''',\n",
    "    \n",
    "    'optimizer': '''You are an AWS Resource Optimization specialist focused on helping users reduce cloud costs.\n",
    "\n",
    "Your capabilities include:\n",
    "1. Identifying underutilized or idle resources\n",
    "2. Recommending right-sizing opportunities\n",
    "3. Suggesting cost-saving architectural changes\n",
    "4. Calculating potential savings from optimizations\n",
    "\n",
    "When providing recommendations:\n",
    "- Include specific resource IDs and configurations\n",
    "- Provide estimated monthly and annual savings\n",
    "- Assess performance impact and implementation difficulty\n",
    "- Prioritize by potential savings and ease of implementation\n",
    "\n",
    "Always validate recommendations against actual usage patterns.''',\n",
    "    \n",
    "    'forecaster': '''You are an AWS Cost Forecasting expert specializing in predictive analytics.\n",
    "\n",
    "Your capabilities include:\n",
    "1. Forecasting future costs based on historical trends\n",
    "2. Identifying growth patterns and seasonality\n",
    "3. Setting up budget alerts and thresholds\n",
    "4. Predicting cost impacts of planned changes\n",
    "\n",
    "When providing forecasts:\n",
    "- Base predictions on historical data and trends\n",
    "- Include confidence levels with predictions\n",
    "- Account for seasonal variations and growth rates\n",
    "- Recommend appropriate budget thresholds\n",
    "\n",
    "Help users plan their cloud spending proactively.'''\n",
    "}\n",
    "\n",
    "# Create agents\n",
    "created_agents = {}\n",
    "\n",
    "agent_configs = [\n",
    "    {\n",
    "        'name': 'FinOps-CostAnalyzer',\n",
    "        'type': 'cost_analyzer',\n",
    "        'model': 'anthropic.claude-3-sonnet-20240229-v1:0'\n",
    "    },\n",
    "    {\n",
    "        'name': 'FinOps-Optimizer',\n",
    "        'type': 'optimizer',\n",
    "        'model': 'anthropic.claude-3-sonnet-20240229-v1:0'\n",
    "    },\n",
    "    {\n",
    "        'name': 'FinOps-Forecaster',\n",
    "        'type': 'forecaster',\n",
    "        'model': 'anthropic.claude-3-sonnet-20240229-v1:0'\n",
    "    }\n",
    "]\n",
    "\n",
    "for config in agent_configs:\n",
    "    try:\n",
    "        # Create the agent\n",
    "        response = bedrock_agent.create_agent(\n",
    "            agentName=config['name'],\n",
    "            agentResourceRoleArn=f\"arn:aws:iam::{account_id}:role/BedrockAgentRole\",\n",
    "            description=f\"AI-powered {config['type'].replace('_', ' ')} for FinOps\",\n",
    "            idleSessionTTLInSeconds=1800,\n",
    "            foundationModel=config['model'],\n",
    "            instruction=agent_instructions[config['type']],\n",
    "            tags={\n",
    "                'Project': 'FinOps',\n",
    "                'Type': config['type']\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        agent_id = response['agent']['agentId']\n",
    "        created_agents[config['type']] = {\n",
    "            'id': agent_id,\n",
    "            'name': config['name'],\n",
    "            'arn': response['agent']['agentArn']\n",
    "        }\n",
    "        \n",
    "        print(f\"Created agent: {config['name']} (ID: {agent_id})\")\n",
    "        \n",
    "        # Prepare the agent\n",
    "        bedrock_agent.prepare_agent(agentId=agent_id)\n",
    "        print(f\"Prepared agent: {config['name']}\")\n",
    "        \n",
    "        time.sleep(5)  # Wait for agent preparation\n",
    "        \n",
    "    except ClientError as e:\n",
    "        print(f\"Error creating agent {config['name']}: {e}\")\n",
    "        if e.response['Error']['Code'] == 'ConflictException':\n",
    "            print(\"Agent may already exist\")\n",
    "\n",
    "print(\"\\nCreated agents:\")\n",
    "for agent_type, agent_info in created_agents.items():\n",
    "    print(f\"  {agent_type}: {agent_info['name']} (ID: {agent_info['id']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "create-action-groups",
   "metadata": {},
   "source": [
    "### Create Action Groups for Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-agent-action-groups",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create action groups for each agent\n",
    "action_group_configs = [\n",
    "    {\n",
    "        'agent_type': 'cost_analyzer',\n",
    "        'action_group_name': 'CostAnalysisActions',\n",
    "        'lambda_arn': deployed_functions['finops-cost-analysis'],\n",
    "        'api_schema_key': 'api-schemas/cost-analysis-api.json'\n",
    "    },\n",
    "    {\n",
    "        'agent_type': 'optimizer',\n",
    "        'action_group_name': 'OptimizationActions',\n",
    "        'lambda_arn': deployed_functions['finops-optimization'],\n",
    "        'api_schema_key': 'api-schemas/optimization-api.json'\n",
    "    },\n",
    "    {\n",
    "        'agent_type': 'forecaster',\n",
    "        'action_group_name': 'ForecastingActions',\n",
    "        'lambda_arn': deployed_functions['finops-forecasting'],\n",
    "        'api_schema_key': 'api-schemas/forecasting-api.json'\n",
    "    }\n",
    "]\n",
    "\n",
    "for config in action_group_configs:\n",
    "    if config['agent_type'] in created_agents:\n",
    "        agent_id = created_agents[config['agent_type']]['id']\n",
    "        \n",
    "        try:\n",
    "            # Create action group\n",
    "            response = bedrock_agent.create_agent_action_group(\n",
    "                agentId=agent_id,\n",
    "                agentVersion='DRAFT',\n",
    "                actionGroupName=config['action_group_name'],\n",
    "                actionGroupExecutor={\n",
    "                    'lambda': config['lambda_arn']\n",
    "                },\n",
    "                apiSchema={\n",
    "                    's3': {\n",
    "                        's3BucketName': os.environ['FINOPS_BUCKET'],\n",
    "                        's3ObjectKey': config['api_schema_key']\n",
    "                    }\n",
    "                },\n",
    "                description=f\"Action group for {config['agent_type'].replace('_', ' ')}\"\n",
    "            )\n",
    "            \n",
    "            print(f\"Created action group '{config['action_group_name']}' for {config['agent_type']}\")\n",
    "            \n",
    "            # Prepare agent again after adding action group\n",
    "            bedrock_agent.prepare_agent(agentId=agent_id)\n",
    "            print(f\"Re-prepared agent after adding action group\")\n",
    "            \n",
    "            time.sleep(5)\n",
    "            \n",
    "        except ClientError as e:\n",
    "            print(f\"Error creating action group: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "create-agent-aliases",
   "metadata": {},
   "source": [
    "### Create Agent Aliases for Production Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-aliases",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create aliases for agents\n",
    "agent_aliases = {}\n",
    "\n",
    "for agent_type, agent_info in created_agents.items():\n",
    "    try:\n",
    "        response = bedrock_agent.create_agent_alias(\n",
    "            agentId=agent_info['id'],\n",
    "            agentAliasName='production',\n",
    "            description=f\"Production alias for {agent_type}\",\n",
    "            tags={\n",
    "                'Environment': 'production',\n",
    "                'Type': agent_type\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        agent_aliases[agent_type] = response['agentAlias']['agentAliasId']\n",
    "        print(f\"Created production alias for {agent_type}: {response['agentAlias']['agentAliasId']}\")\n",
    "        \n",
    "    except ClientError as e:\n",
    "        print(f\"Error creating alias: {e}\")\n",
    "\n",
    "# Store agent information for later use\n",
    "finops_agents = {\n",
    "    agent_type: {\n",
    "        'id': agent_info['id'],\n",
    "        'name': agent_info['name'],\n",
    "        'alias': agent_aliases.get(agent_type, 'TSTALIASID'),\n",
    "        'arn': agent_info['arn']\n",
    "    }\n",
    "    for agent_type, agent_info in created_agents.items()\n",
    "}\n",
    "\n",
    "print(\"\\nFinOps Agents Configuration:\")\n",
    "print(json.dumps(finops_agents, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test-agents",
   "metadata": {},
   "source": [
    "## 7. Test the Deployed Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-agent-invocation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import uuid\n",
    "\n",
    "bedrock_runtime = boto3.client('bedrock-agent-runtime')\n",
    "\n",
    "def invoke_agent(agent_type, prompt):\n",
    "    \"\"\"\n",
    "    Invoke a Bedrock agent with a prompt\n",
    "    \"\"\"\n",
    "    if agent_type not in finops_agents:\n",
    "        print(f\"Unknown agent type: {agent_type}\")\n",
    "        return None\n",
    "    \n",
    "    agent_config = finops_agents[agent_type]\n",
    "    session_id = str(uuid.uuid4())\n",
    "    \n",
    "    try:\n",
    "        response = bedrock_runtime.invoke_agent(\n",
    "            agentId=agent_config['id'],\n",
    "            agentAliasId=agent_config['alias'],\n",
    "            sessionId=session_id,\n",
    "            inputText=prompt\n",
    "        )\n",
    "        \n",
    "        # Process response\n",
    "        result = \"\"\n",
    "        for event in response.get('completion', []):\n",
    "            if 'chunk' in event:\n",
    "                chunk = event['chunk']\n",
    "                if 'bytes' in chunk:\n",
    "                    result += chunk['bytes'].decode('utf-8')\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error invoking agent: {e}\")\n",
    "        return None\n",
    "\n",
    "# Test each agent\n",
    "test_prompts = {\n",
    "    'cost_analyzer': \"What are my top 5 AWS services by cost in the last 7 days?\",\n",
    "    'optimizer': \"Find idle EC2 instances and recommend optimization actions\",\n",
    "    'forecaster': \"Forecast my AWS costs for the next 3 months based on current trends\"\n",
    "}\n",
    "\n",
    "print(\"Testing deployed agents...\\n\")\n",
    "\n",
    "for agent_type, prompt in test_prompts.items():\n",
    "    if agent_type in finops_agents:\n",
    "        print(f\"Testing {agent_type} agent...\")\n",
    "        print(f\"Prompt: {prompt}\")\n",
    "        \n",
    "        result = invoke_agent(agent_type, prompt)\n",
    "        if result:\n",
    "            print(f\"Response: {result[:500]}...\\n\")  # Show first 500 chars\n",
    "        else:\n",
    "            print(\"No response received\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "multi-agent-orchestration",
   "metadata": {},
   "source": [
    "## 8. Multi-Agent Orchestration Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "orchestration-example",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinOpsMultiAgentOrchestrator:\n",
    "    \"\"\"\n",
    "    Orchestrates multiple Bedrock agents for complex FinOps tasks\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, agents_config):\n",
    "        self.bedrock_runtime = boto3.client('bedrock-agent-runtime')\n",
    "        self.agents = agents_config\n",
    "        self.session_attributes = {}\n",
    "    \n",
    "    def process_complex_request(self, user_request):\n",
    "        \"\"\"\n",
    "        Process a complex request that requires multiple agents\n",
    "        \"\"\"\n",
    "        print(f\"Processing complex request: {user_request}\\n\")\n",
    "        \n",
    "        # Step 1: Analyze current costs\n",
    "        print(\"Step 1: Analyzing current costs...\")\n",
    "        cost_analysis = self._invoke_agent(\n",
    "            'cost_analyzer',\n",
    "            \"Analyze my AWS costs for the last 30 days and identify the top cost drivers\"\n",
    "        )\n",
    "        print(f\"Cost Analysis: {cost_analysis[:300]}...\\n\")\n",
    "        \n",
    "        # Step 2: Get optimization recommendations based on cost analysis\n",
    "        print(\"Step 2: Getting optimization recommendations...\")\n",
    "        optimization_prompt = f\"\"\"Based on the cost analysis showing high costs, \n",
    "        provide specific optimization recommendations for reducing costs.\n",
    "        Focus on the highest cost services.\"\"\"\n",
    "        \n",
    "        optimizations = self._invoke_agent('optimizer', optimization_prompt)\n",
    "        print(f\"Optimizations: {optimizations[:300]}...\\n\")\n",
    "        \n",
    "        # Step 3: Forecast savings impact\n",
    "        print(\"Step 3: Forecasting cost impact...\")\n",
    "        forecast_prompt = \"\"\"Based on the optimization recommendations, \n",
    "        forecast the potential cost savings over the next 3 months \n",
    "        if these optimizations are implemented.\"\"\"\n",
    "        \n",
    "        forecast = self._invoke_agent('forecaster', forecast_prompt)\n",
    "        print(f\"Forecast: {forecast[:300]}...\\n\")\n",
    "        \n",
    "        # Synthesize results\n",
    "        return {\n",
    "            'cost_analysis': cost_analysis,\n",
    "            'optimizations': optimizations,\n",
    "            'forecast': forecast,\n",
    "            'summary': self._create_summary(cost_analysis, optimizations, forecast)\n",
    "        }\n",
    "    \n",
    "    def _invoke_agent(self, agent_type, prompt):\n",
    "        \"\"\"\n",
    "        Invoke a specific agent\n",
    "        \"\"\"\n",
    "        agent_config = self.agents.get(agent_type)\n",
    "        if not agent_config:\n",
    "            return \"Agent not found\"\n",
    "        \n",
    "        session_id = self.session_attributes.get('session_id', str(uuid.uuid4()))\n",
    "        self.session_attributes['session_id'] = session_id\n",
    "        \n",
    "        try:\n",
    "            response = self.bedrock_runtime.invoke_agent(\n",
    "                agentId=agent_config['id'],\n",
    "                agentAliasId=agent_config['alias'],\n",
    "                sessionId=session_id,\n",
    "                inputText=prompt\n",
    "            )\n",
    "            \n",
    "            result = \"\"\n",
    "            for event in response.get('completion', []):\n",
    "                if 'chunk' in event:\n",
    "                    chunk = event['chunk']\n",
    "                    if 'bytes' in chunk:\n",
    "                        result += chunk['bytes'].decode('utf-8')\n",
    "            \n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            return f\"Error: {str(e)}\"\n",
    "    \n",
    "    def _create_summary(self, cost_analysis, optimizations, forecast):\n",
    "        \"\"\"\n",
    "        Create a summary of the multi-agent analysis\n",
    "        \"\"\"\n",
    "        return f\"\"\"FinOps Analysis Summary:\n",
    "\n",
    "1. Current State: The cost analysis reveals your AWS spending patterns and identifies key cost drivers.\n",
    "\n",
    "2. Optimization Opportunities: Multiple optimization strategies have been identified that could significantly reduce your AWS costs.\n",
    "\n",
    "3. Projected Impact: If implemented, these optimizations are forecasted to provide substantial cost savings over the coming months.\n",
    "\n",
    "This multi-agent analysis provides a comprehensive view of your current costs, actionable optimization strategies, and projected savings.\"\"\"\n",
    "\n",
    "# Test multi-agent orchestration\n",
    "orchestrator = FinOpsMultiAgentOrchestrator(finops_agents)\n",
    "\n",
    "complex_request = \"\"\"I need a comprehensive FinOps analysis: \n",
    "1. What are my current AWS costs and trends?\n",
    "2. Where can I optimize to reduce costs?\n",
    "3. What would be the impact of these optimizations?\"\"\"\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Multi-Agent FinOps Analysis\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "results = orchestrator.process_complex_request(complex_request)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Analysis Summary\")\n",
    "print(\"=\"*60)\n",
    "print(results['summary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleanup",
   "metadata": {},
   "source": [
    "## 9. Summary and Next Steps\n",
    "\n",
    "### What We've Accomplished\n",
    "\n",
    "1. **Created IAM Roles**: Set up necessary permissions for Bedrock agents and Lambda functions\n",
    "2. **Deployed Lambda Functions**: Created and deployed three Lambda functions for cost analysis, optimization, and forecasting\n",
    "3. **Created Bedrock Agents**: Deployed three specialized AI agents with specific prompts and models\n",
    "4. **Configured Action Groups**: Connected agents to Lambda functions through API schemas\n",
    "5. **Tested Integration**: Verified that agents can invoke Lambda functions and return results\n",
    "6. **Demonstrated Multi-Agent Orchestration**: Showed how multiple agents can work together\n",
    "\n",
    "### Architecture Summary\n",
    "\n",
    "```\n",
    "User Request\n",
    "     ↓\n",
    "Bedrock Agent (with LLM)\n",
    "     ↓\n",
    "Action Group (API Schema)\n",
    "     ↓\n",
    "Lambda Function\n",
    "     ↓\n",
    "AWS Services (Cost Explorer, EC2, CloudWatch, etc.)\n",
    "```\n",
    "\n",
    "### Key Components Created\n",
    "\n",
    "1. **Lambda Functions**:\n",
    "   - `finops-cost-analysis`: Analyzes costs and identifies anomalies\n",
    "   - `finops-optimization`: Finds optimization opportunities\n",
    "   - `finops-forecasting`: Predicts future costs\n",
    "\n",
    "2. **Bedrock Agents**:\n",
    "   - **Cost Analyzer**: Specialized in cost analysis and reporting\n",
    "   - **Optimizer**: Focused on resource optimization recommendations\n",
    "   - **Forecaster**: Handles cost predictions and budget planning\n",
    "\n",
    "3. **Action Groups**: Each agent has its own action group connecting to the appropriate Lambda function\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Enhance Lambda Functions**: Add more sophisticated analysis and optimization logic\n",
    "2. **Integrate with Your Tools**: Connect to your existing FinOps dashboards and tools\n",
    "3. **Add More Agents**: Create specialized agents for specific use cases (e.g., security cost analysis)\n",
    "4. **Implement Feedback Loop**: Use agent outputs to continuously improve recommendations\n",
    "5. **Set Up Monitoring**: Track agent usage, costs, and performance\n",
    "6. **Create UI**: Build a web interface or Slack bot for easier interaction\n",
    "\n",
    "### Save Configuration for Future Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save-config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save configuration for future use\n",
    "config = {\n",
    "    'bucket': os.environ['FINOPS_BUCKET'],\n",
    "    'region': os.environ['AWS_DEFAULT_REGION'],\n",
    "    'agents': finops_agents,\n",
    "    'lambda_functions': deployed_functions,\n",
    "    'account_id': account_id\n",
    "}\n",
    "\n",
    "# Save to file\n",
    "with open('finops_config.json', 'w') as f:\n",
    "    json.dump(config, f, indent=2)\n",
    "\n",
    "print(\"Configuration saved to finops_config.json\")\n",
    "print(\"\\nYour FinOps AI Platform is now fully deployed and ready to use!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2mjm160ex9n",
   "source": "## 10. Streamlit Dashboard with Integrated Chatbot <a name=\"chatbot\"></a>\n\n### Overview\nThe enhanced FinOps dashboard now includes an integrated AI-powered chatbot that can:\n- Answer questions about AWS costs in natural language\n- Provide real-time cost analysis using cached data\n- Integrate with Bedrock agents for advanced insights\n- Work seamlessly with Lambda functions and MCP\n\n### Key Features of the Chatbot Integration\n\n1. **Natural Language Interface**: Users can ask questions like:\n   - \"What are my highest costs this month?\"\n   - \"Which services are growing fastest?\"\n   - \"How can I reduce my EC2 costs?\"\n\n2. **Real-time Data Integration**: The chatbot has access to:\n   - Current cost data from AWS Cost Explorer\n   - EC2 utilization metrics\n   - Historical cost trends\n   - Optimization recommendations\n\n3. **AI-Powered Responses**: Uses either:\n   - AWS Bedrock agents for advanced analysis\n   - Fallback responses with real data when AI services are unavailable\n\n4. **Context Awareness**: Maintains conversation history and understands follow-up questions",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "h6he4tmhswa",
   "source": "### Chatbot Implementation Code\n\nThe chatbot is implemented in the enhanced dashboard (`finops_dashboard_with_chatbot.py`). Here's how it works:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "lqa4sgx574",
   "source": "# Key chatbot components from finops_dashboard_with_chatbot.py\n\n# 1. Session State Initialization\ndef initialize_chat_session():\n    \"\"\"Initialize chat session state\"\"\"\n    if 'chat_messages' not in st.session_state:\n        st.session_state.chat_messages = []\n    if 'cost_data_cache' not in st.session_state:\n        st.session_state.cost_data_cache = None\n    if 'chat_mode' not in st.session_state:\n        st.session_state.chat_mode = False\n\n# 2. Bedrock Agent Integration\ndef query_bedrock_agent(prompt):\n    \"\"\"Query Bedrock agent for AI insights\"\"\"\n    if not AGENT_ID or not AGENT_ALIAS:\n        return \"Bedrock agent not configured. Using fallback analysis.\"\n    \n    try:\n        session_id = str(uuid.uuid4())\n        \n        response = bedrock_runtime.invoke_agent(\n            agentId=AGENT_ID,\n            agentAliasId=AGENT_ALIAS,\n            sessionId=session_id,\n            inputText=prompt\n        )\n        \n        # Process streaming response\n        result = \"\"\n        for event in response.get('completion', []):\n            if 'chunk' in event:\n                chunk = event['chunk']\n                if 'bytes' in chunk:\n                    result += chunk['bytes'].decode('utf-8')\n        \n        return result if result else \"No response from agent.\"\n        \n    except Exception as e:\n        return f\"Using fallback analysis due to: {str(e)}\"\n\n# 3. Lambda Function Integration\ndef invoke_lambda_for_insights(function_name, parameters):\n    \"\"\"Invoke Lambda function for specific insights\"\"\"\n    event = {\n        'apiPath': f'/{function_name}',\n        'parameters': parameters,\n        'actionGroup': 'chat',\n        'httpMethod': 'POST'\n    }\n    \n    try:\n        response = lambda_client.invoke(\n            FunctionName='finops-cost-analysis',\n            InvocationType='RequestResponse',\n            Payload=json.dumps(event)\n        )\n        \n        result = json.loads(response['Payload'].read())\n        \n        if 'response' in result and 'responseBody' in result['response']:\n            body = result['response']['responseBody']['application/json']['body']\n            return json.loads(body)\n        else:\n            return result\n            \n    except Exception as e:\n        return {'error': str(e)}\n\n# 4. Fallback Response Generator\ndef generate_fallback_response(prompt, cost_data):\n    \"\"\"Generate response using cached data when AI is unavailable\"\"\"\n    prompt_lower = prompt.lower()\n    \n    if not cost_data:\n        return \"I don't have any cost data available. Please refresh the dashboard.\"\n    \n    # Analyze prompt intent\n    if 'highest' in prompt_lower or 'top' in prompt_lower:\n        # Get top services by cost\n        services = cost_data.get('services_by_cost', {})\n        top_5 = list(services.items())[:5]\n        \n        response = \"Based on your current data, here are your top 5 services by cost:\\\\n\\\\n\"\n        for i, (service, cost) in enumerate(top_5, 1):\n            response += f\"{i}. **{service}**: ${cost:,.2f}\\\\n\"\n        \n        response += f\"\\\\nTotal cost for the period: ${cost_data.get('total_cost', 0):,.2f}\"\n        \n    elif 'save' in prompt_lower or 'reduce' in prompt_lower:\n        # Provide optimization tips\n        response = \"Here are some cost optimization recommendations:\\\\n\\\\n\"\n        response += \"1. **Right-size EC2 instances** - Review underutilized instances\\\\n\"\n        response += \"2. **Use Reserved Instances** - Save up to 72% on predictable workloads\\\\n\"\n        response += \"3. **Enable S3 lifecycle policies** - Move old data to cheaper storage\\\\n\"\n        response += \"4. **Review unattached EBS volumes** - Delete unused storage\\\\n\"\n        response += \"5. **Use Spot instances** - Save up to 90% on fault-tolerant workloads\"\n        \n    elif 'trend' in prompt_lower or 'growing' in prompt_lower:\n        # Analyze trends\n        daily_trend = cost_data.get('daily_trend', [])\n        if len(daily_trend) > 1:\n            first_cost = daily_trend[0]['cost']\n            last_cost = daily_trend[-1]['cost']\n            trend_pct = ((last_cost - first_cost) / first_cost * 100) if first_cost > 0 else 0\n            \n            response = f\"Your costs are {'increasing' if trend_pct > 0 else 'decreasing'} \"\n            response += f\"by {abs(trend_pct):.1f}% over the period.\\\\n\\\\n\"\n            response += f\"First day: ${first_cost:,.2f}\\\\n\"\n            response += f\"Last day: ${last_cost:,.2f}\\\\n\"\n            response += f\"Daily average: ${cost_data.get('daily_average', 0):,.2f}\"\n        else:\n            response = \"Not enough data to analyze trends.\"\n            \n    else:\n        # General cost summary\n        response = f\"Here's your cost summary:\\\\n\\\\n\"\n        response += f\"**Total cost**: ${cost_data.get('total_cost', 0):,.2f}\\\\n\"\n        response += f\"**Daily average**: ${cost_data.get('daily_average', 0):,.2f}\\\\n\"\n        response += f\"**Number of services**: {cost_data.get('service_count', 0)}\\\\n\\\\n\"\n        response += \"Ask me about specific services, trends, or optimization opportunities!\"\n    \n    return response",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "39p91zdsquh",
   "source": "### Dashboard Structure with Chatbot\n\nThe enhanced dashboard includes 6 main tabs:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "jgb0sauucgg",
   "source": "# Dashboard Tab Structure\ntabs = st.tabs([\n    \"📊 Cost Overview\",      # Real-time cost analysis\n    \"📈 Trends\",            # Cost trends and patterns\n    \"🖥️ EC2 Analysis\",      # Instance utilization\n    \"💡 Optimizations\",     # Cost savings recommendations  \n    \"🤖 AI Chat\",          # NEW: Dedicated chatbot interface\n    \"🧪 Test Lambda\"       # Lambda function testing\n])\n\n# AI Chat Tab Implementation\nwith tabs[4]:  # AI Chat tab\n    st.header(\"🤖 AI FinOps Assistant\")\n    st.markdown(\"Ask me anything about your AWS costs!\")\n    \n    # Chat interface\n    chat_container = st.container()\n    \n    with chat_container:\n        # Display chat history\n        for msg in st.session_state.chat_messages:\n            with st.chat_message(msg[\"role\"]):\n                st.markdown(msg[\"content\"])\n    \n    # Chat input\n    if prompt := st.chat_input(\"Ask about your AWS costs...\"):\n        # Add user message\n        st.session_state.chat_messages.append({\"role\": \"user\", \"content\": prompt})\n        \n        with st.chat_message(\"user\"):\n            st.markdown(prompt)\n        \n        # Get AI response\n        with st.chat_message(\"assistant\"):\n            with st.spinner(\"Analyzing...\"):\n                # Update cost data cache if needed\n                if not st.session_state.cost_data_cache:\n                    cost_data = get_cost_data(7)\n                    if cost_data:\n                        # Process and cache the data\n                        st.session_state.cost_data_cache = process_cost_data(cost_data)\n                \n                # Try Bedrock agent first\n                ai_response = query_bedrock_agent(prompt)\n                \n                # If Bedrock fails, use fallback with real data\n                if \"fallback\" in ai_response.lower() or \"error\" in ai_response.lower():\n                    ai_response = generate_fallback_response(\n                        prompt, \n                        st.session_state.cost_data_cache\n                    )\n                \n                st.markdown(ai_response)\n                \n        # Add assistant message to history\n        st.session_state.chat_messages.append({\n            \"role\": \"assistant\", \n            \"content\": ai_response\n        })",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "il504z63xs",
   "source": "### Enhanced Chat Mode\n\nThe dashboard also includes an enhanced chat mode that can be toggled from the sidebar:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "v36zbqxrxtc",
   "source": "# Enhanced Chat Mode Feature\nwith st.sidebar:\n    st.header(\"Configuration\")\n    days = st.slider(\"Analysis Period (days)\", 1, 90, 7)\n    \n    # NEW: Enhanced chat mode toggle\n    st.markdown(\"---\")\n    st.markdown(\"### 💬 Chat Mode\")\n    chat_mode = st.toggle(\n        \"Enable Enhanced Chat\",\n        value=st.session_state.get('chat_mode', False),\n        help=\"Toggle to focus on AI chat interface\"\n    )\n    \n    if chat_mode != st.session_state.get('chat_mode', False):\n        st.session_state.chat_mode = chat_mode\n        st.rerun()\n    \n    if chat_mode:\n        st.info(\"Chat mode enabled! The AI assistant has full context of your cost data.\")\n        \n        # Quick prompts in chat mode\n        st.markdown(\"#### Quick Prompts\")\n        quick_prompts = [\n            \"What are my top 5 costs?\",\n            \"How can I reduce EC2 costs?\",\n            \"Show me cost trends\",\n            \"Find idle resources\",\n            \"Forecast next month's costs\"\n        ]\n        \n        for prompt in quick_prompts:\n            if st.button(f\"📝 {prompt}\", key=f\"quick_{prompt}\"):\n                # This would add the prompt to the chat\n                st.session_state.pending_prompt = prompt\n                st.rerun()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "b7dedqgykyo",
   "source": "### Export Functionality\n\nThe chatbot-enhanced dashboard includes comprehensive export capabilities:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "8fohqmazh4r",
   "source": "# Export Functionality\ndef export_data(format_type, data):\n    \"\"\"Export dashboard data in various formats\"\"\"\n    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n    \n    if format_type == \"CSV\":\n        # Prepare CSV data\n        df = pd.DataFrame()\n        \n        # Add cost summary\n        if 'total_cost' in data:\n            df['Metric'] = ['Total Cost', 'Daily Average', 'Service Count']\n            df['Value'] = [\n                f\"${data['total_cost']:,.2f}\",\n                f\"${data['daily_average']:,.2f}\",\n                data['service_count']\n            ]\n        \n        # Add services data\n        if 'services_by_cost' in data:\n            services_df = pd.DataFrame(\n                list(data['services_by_cost'].items()),\n                columns=['Service', 'Cost']\n            )\n            services_df['Cost'] = services_df['Cost'].apply(lambda x: f\"${x:,.2f}\")\n        \n        # Export CSV\n        csv_buffer = io.StringIO()\n        df.to_csv(csv_buffer, index=False)\n        csv_data = csv_buffer.getvalue()\n        \n        st.download_button(\n            label=\"📥 Download CSV\",\n            data=csv_data,\n            file_name=f\"finops_report_{timestamp}.csv\",\n            mime=\"text/csv\"\n        )\n    \n    elif format_type == \"JSON\":\n        # Export full data as JSON\n        json_data = json.dumps(data, indent=2, default=str)\n        \n        st.download_button(\n            label=\"📥 Download JSON\",\n            data=json_data,\n            file_name=f\"finops_report_{timestamp}.json\",\n            mime=\"application/json\"\n        )\n    \n    elif format_type == \"PDF\":\n        # Generate PDF summary\n        pdf_content = f\\\"\\\"\\\"\n# FinOps Cost Report\nGenerated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n## Executive Summary\n- Total Cost: ${data.get('total_cost', 0):,.2f}\n- Daily Average: ${data.get('daily_average', 0):,.2f}\n- Number of Services: {data.get('service_count', 0)}\n- Analysis Period: {data.get('period', 'N/A')}\n\n## Top Services by Cost\n\\\"\\\"\\\"\n        if 'services_by_cost' in data:\n            for i, (service, cost) in enumerate(\n                list(data['services_by_cost'].items())[:10], 1\n            ):\n                pdf_content += f\"{i}. {service}: ${cost:,.2f}\\\\n\"\n        \n        pdf_content += \\\"\\\"\\\"\n## Cost Optimization Recommendations\n1. Review and right-size underutilized EC2 instances\n2. Implement Reserved Instances for stable workloads\n3. Enable S3 lifecycle policies for data archival\n4. Review and delete unattached EBS volumes\n5. Consider using Spot instances for fault-tolerant applications\n\n## AI Assistant Insights\nThe integrated AI chatbot can provide:\n- Real-time cost analysis and trends\n- Personalized optimization recommendations\n- Cost forecasting and budget planning\n- Resource utilization insights\n\\\"\\\"\\\"\n        \n        # For demo, show PDF content\n        st.text_area(\"PDF Preview\", pdf_content, height=400)\n        st.info(\"Full PDF export functionality would be implemented with reportlab or similar library\")\n\n# Export section in sidebar\nwith st.sidebar:\n    st.markdown(\"---\")\n    st.markdown(\"### 📤 Export Data\")\n    \n    export_format = st.selectbox(\n        \"Export Format\",\n        [\"CSV\", \"JSON\", \"PDF Summary\"]\n    )\n    \n    if st.button(\"Export Report\"):\n        # Prepare export data\n        export_data_dict = {\n            'total_cost': st.session_state.get('total_cost', 0),\n            'daily_average': st.session_state.get('daily_average', 0),\n            'service_count': st.session_state.get('service_count', 0),\n            'services_by_cost': st.session_state.get('services_by_cost', {}),\n            'period': f\"{days} days\",\n            'export_date': datetime.now().isoformat(),\n            'chat_history': st.session_state.get('chat_messages', [])\n        }\n        \n        if export_format == \"PDF Summary\":\n            export_data(\"PDF\", export_data_dict)\n        else:\n            export_data(export_format, export_data_dict)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "p7vtds4v9d",
   "source": "### Running the Enhanced Dashboard\n\nTo run the dashboard with chatbot integration:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "ivkj1aledus",
   "source": "# Running the Enhanced Dashboard\n\n# 1. Ensure all dependencies are installed\n!pip install streamlit boto3 pandas plotly\n\n# 2. Set up AWS credentials (if not already configured)\n# aws configure\n\n# 3. Run the dashboard\n# In terminal:\n# streamlit run finops_dashboard_with_chatbot.py\n\n# 4. Access the dashboard at http://localhost:8501\n\n# Key features to test:\n# - Navigate to the AI Chat tab\n# - Ask questions about your costs\n# - Try the enhanced chat mode toggle in the sidebar\n# - Test export functionality\n# - Use quick prompts for common queries\n\n# Example queries for the chatbot:\nexample_queries = [\n    \"What are my top 5 AWS services by cost?\",\n    \"How much am I spending on EC2 instances?\",\n    \"Show me my cost trend for the last week\",\n    \"Which services are growing fastest?\",\n    \"How can I reduce my AWS costs?\",\n    \"Find underutilized EC2 instances\",\n    \"What's my daily average spend?\",\n    \"Forecast my costs for next month\",\n    \"Are there any cost anomalies?\",\n    \"What percentage of my costs is from S3?\"\n]\n\nprint(\"Example queries you can ask the chatbot:\")\nfor i, query in enumerate(example_queries, 1):\n    print(f\"{i}. {query}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "mhw4qm42nm",
   "source": "### Integration with MCP Server\n\nThe chatbot can also integrate with the MCP (Model Context Protocol) server for enhanced AI capabilities:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "543r047d21u",
   "source": "# MCP Integration for Enhanced AI Capabilities\n\nimport websocket\nimport json\n\nclass MCPChatbotIntegration:\n    \"\"\"Integrate chatbot with MCP server for enhanced capabilities\"\"\"\n    \n    def __init__(self, mcp_url=\"ws://localhost:8765\"):\n        self.mcp_url = mcp_url\n        self.ws = None\n        self.connect()\n    \n    def connect(self):\n        \"\"\"Connect to MCP server\"\"\"\n        try:\n            self.ws = websocket.create_connection(self.mcp_url)\n            print(\"Connected to MCP server\")\n        except Exception as e:\n            print(f\"Failed to connect to MCP: {e}\")\n            self.ws = None\n    \n    def query_mcp_tool(self, tool_name, parameters):\n        \"\"\"Query a specific MCP tool\"\"\"\n        if not self.ws:\n            return {\"error\": \"MCP not connected\"}\n        \n        request = {\n            \"type\": \"tool_call\",\n            \"tool\": tool_name,\n            \"parameters\": parameters\n        }\n        \n        try:\n            self.ws.send(json.dumps(request))\n            response = json.loads(self.ws.recv())\n            return response\n        except Exception as e:\n            return {\"error\": str(e)}\n    \n    def enhance_chatbot_response(self, user_prompt, base_response):\n        \"\"\"Enhance chatbot response using MCP tools\"\"\"\n        prompt_lower = user_prompt.lower()\n        \n        # Determine which MCP tool to use\n        if \"forecast\" in prompt_lower or \"predict\" in prompt_lower:\n            # Use forecasting tool\n            mcp_result = self.query_mcp_tool(\n                \"forecast_costs\",\n                {\"months\": 3}\n            )\n        elif \"optimize\" in prompt_lower or \"save\" in prompt_lower:\n            # Use optimization tool\n            mcp_result = self.query_mcp_tool(\n                \"get_optimization_recommendations\",\n                {\"resource_type\": \"all\"}\n            )\n        else:\n            # Use general cost analysis\n            mcp_result = self.query_mcp_tool(\n                \"get_cost_analysis\",\n                {\"days\": 7}\n            )\n        \n        # Combine MCP insights with base response\n        if \"error\" not in mcp_result:\n            enhanced_response = f\"{base_response}\\\\n\\\\n\"\n            enhanced_response += \"**Additional AI Insights from MCP:**\\\\n\"\n            enhanced_response += json.dumps(mcp_result, indent=2)\n            return enhanced_response\n        \n        return base_response\n\n# Usage in the chatbot\ndef enhanced_chatbot_with_mcp(prompt):\n    \"\"\"Enhanced chatbot that uses both Bedrock and MCP\"\"\"\n    \n    # Get base response from Bedrock or fallback\n    base_response = query_bedrock_agent(prompt)\n    \n    # Try to enhance with MCP if available\n    try:\n        mcp_integration = MCPChatbotIntegration()\n        enhanced_response = mcp_integration.enhance_chatbot_response(\n            prompt, \n            base_response\n        )\n        return enhanced_response\n    except:\n        # If MCP fails, return base response\n        return base_response\n\n# Example usage\nif __name__ == \"__main__\":\n    # Test enhanced chatbot\n    test_prompt = \"What are my optimization opportunities?\"\n    response = enhanced_chatbot_with_mcp(test_prompt)\n    print(response)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "lm2bgvym03",
   "source": "### Summary of Chatbot Integration\n\nThe integrated chatbot provides:\n\n1. **Natural Language Interface**: Users can ask questions in plain English\n2. **Real-time Data Access**: Always uses current AWS cost data\n3. **AI-Powered Analysis**: Leverages Bedrock agents for intelligent insights\n4. **Fallback Mechanisms**: Works even if AI services are unavailable\n5. **Context Awareness**: Maintains conversation history\n6. **Export Capabilities**: Can export chat history and insights\n7. **MCP Integration**: Can use external AI tools for enhanced capabilities\n8. **Enhanced Chat Mode**: Dedicated interface for AI interactions\n\nThe chatbot seamlessly integrates with all existing FinOps components:\n- Lambda functions for data processing\n- Bedrock agents for AI analysis\n- MCP server for external tool access\n- Real AWS APIs for accurate data\n\nThis creates a powerful, unified platform for AI-driven FinOps management.",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}